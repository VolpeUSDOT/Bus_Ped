{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate products\n",
    "\n",
    "Follows Step 4, `04_add_stop_times_to_db.ipynb`\n",
    "\n",
    "**In process for `ituran_synchromatics_data.sqlite` in Data Integration - All Months**\n",
    "\n",
    "This script creates or replaces a table in the database at the supplied\n",
    "path that contains the set of stops for each of five Downtown DASH routes\n",
    "\n",
    "This script creates or replaces two tables in the database at the supplied\n",
    "path that contain 'clean' subsets of LADOT DASH trip data, where a clean trip is\n",
    "defined as having a pair of 'terminal' stops with a sequence of all northbound\n",
    "stops followed by all southbound stops (or vice versa) in between, and having\n",
    "a number of stop events no greater than the total number of stops that\n",
    "constitute a round trip on the route. A terminal stop is a stop where drivers\n",
    "transition their shifts.\n",
    "\n",
    "TODO: resolve issues that prevent all stop events from being included in the\n",
    "data product, e.g. when buses return to a depo from a stop other than the\n",
    "terminal, or when a driver running multiple contiguous rounds trips in a\n",
    "single shift does not stop at the terminal between two bounds.\n",
    "\n",
    "The hotspot_data_product table contains per-warning records for the purpose of\n",
    "hotspot analysis and the longitudinal_data_product table contains per-trip\n",
    "records, with warnings aggegated into counts for the purpose of longitudinal\n",
    "analysis.\n",
    "\n",
    "Data product construction is performed in three phases. First, individual trips\n",
    "are identified in construct_trip_list(), then corresponding warnings are\n",
    "assigned to each trip based on a time range and a vehicle id in\n",
    "assign_warnings_to_trips(), and finally either a hotspot or a longitudinal data\n",
    "product is constructed given the trips and their warnings in\n",
    "construct_hotspot_data_product() or construct_longitudinal_data_product()\n",
    "\n",
    "TODO: log print statements\n",
    "TODO: only db read stop events in the date range across driver schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunk by month and multiprocess**\n",
    "\n",
    "In process. Idea now (2019-04-01) is to split the job into tasks by month, then use `multiprocessing` to process multiple month at a time. \n",
    "\n",
    "Start with batching by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted from parser, adding project root dir\n",
    "project_root_dir = r'\\\\vntscex.local\\DFS\\3BC-Share$_Mobileye_Data\\Data\\Data Integration - All Months' \n",
    "\n",
    "db_path='ituran_synchromatics_data.sqlite'\n",
    "route_stop_table_name='route_stop'\n",
    "stop_event_table_name='stop_time'\n",
    "driver_schedule_table_name='vehicle_assignment'\n",
    "warning_table_name='warning'\n",
    "hotspot_record_table_name='hotspot_data_product'\n",
    "longitudinal_record_table_name='longitudinal_data_product'\n",
    "if_exists='append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define hostpot table column names and a custom data type fo organizing data\n",
    "# into records\n",
    "hotspot_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'loc_time', 'warning_name', 'latitude', 'longitude'])\n",
    "\n",
    "hotspot_type = np.dtype([\n",
    "  (hotspot_header[0], np.unicode_, 6), (hotspot_header[1], np.uint32),\n",
    "  (hotspot_header[2], np.unicode_, 10), (hotspot_header[3], np.uint32),\n",
    "  (hotspot_header[4], np.uint32), (hotspot_header[5], np.uint32),\n",
    "  (hotspot_header[6], datetime), (hotspot_header[7], np.unicode_, 34),\n",
    "  (hotspot_header[8], np.float64), (hotspot_header[9], np.float64)])\n",
    "\n",
    "# define longitudinal table column names and a custom data type fo organizing\n",
    "# data into records\n",
    "longitudinal_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'start_time', 'end_time', 'ME - Pedestrian Collision Warning',\n",
    "  'ME - Pedestrian In Range Warning', 'PCW-LF', 'PCW-LR', 'PCW-RR',\n",
    "  'PDZ - Left Front', 'PDZ-LR', 'PDZ-R', 'Safety - Braking - Aggressive',\n",
    "  'Safety - Braking - Dangerous'])\n",
    "\n",
    "longitudinal_type = np.dtype([\n",
    "  (longitudinal_header[0], np.unicode_, 6), (longitudinal_header[1], np.uint32),\n",
    "  (longitudinal_header[2], np.unicode_, 10), (longitudinal_header[3], np.uint32),\n",
    "  (longitudinal_header[4], np.uint32), (longitudinal_header[5], np.uint32),\n",
    "  (longitudinal_header[6], datetime),\n",
    "  (longitudinal_header[7], datetime), (longitudinal_header[8], np.uint16),\n",
    "  (longitudinal_header[9], np.uint16), (longitudinal_header[10], np.uint16),\n",
    "  (longitudinal_header[11], np.uint16), (longitudinal_header[12], np.uint16),\n",
    "  (longitudinal_header[13], np.uint16), (longitudinal_header[14], np.uint16),\n",
    "  (longitudinal_header[15], np.uint16), (longitudinal_header[16], np.uint16),\n",
    "  (longitudinal_header[17], np.uint16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a separate collection of warning headers will be used to first create warning\n",
    "# count data before concatenating them with trip data to form longitudinal\n",
    "# records\n",
    "warnings_header = longitudinal_header[8:]\n",
    "\n",
    "valid_trip_count = 0\n",
    "invalid_trip_count = 0\n",
    "pseudo_invalid_trip_count = 0\n",
    "trips_with_no_warnings = 0\n",
    "\n",
    "# a Run object is used to organize an individual trip's properties together with\n",
    "# a collection of warnings that may vary in length from trip to trip\n",
    "class Trip:\n",
    "  def __init__(self, route_name, route_id, heading, vehicle_id, start_time,\n",
    "               end_time, stop_count, driver_id=None, bus_number=None, warnings=None):\n",
    "    self.route_name = route_name\n",
    "    self.route_id = route_id\n",
    "    self.heading = heading\n",
    "    self.vehicle_id = vehicle_id\n",
    "    self.start_time = start_time\n",
    "    self.end_time = end_time\n",
    "    self.driver_id = driver_id\n",
    "    self.bus_number = bus_number\n",
    "    self.warnings = warnings\n",
    "    self.stop_count = stop_count\n",
    "\n",
    "\n",
    "# numpy arrays of custom dtype expect elements to be tuples. Because\n",
    "# longitudinal records are created in batches, organization of data into a tuple\n",
    "# must be applied row-wise across the batch dimension\n",
    "def to_tuple(element):\n",
    "  return np.array(tuple(element), dtype=hotspot_type)\n",
    "\n",
    "\n",
    "def construct_trip_list(route_stops, stop_times):\n",
    "  \"\"\"\n",
    "  Given a time-ordered sequence of stops a bus traveled to or past, and the\n",
    "  arrival time for each stop, extract instances of round trips (between the\n",
    "  departure from a terminal to the arrival at that same stop. Records for which\n",
    "  consecutive terminal stops have an unreasonable number of intermediate stops\n",
    "  (e.g. more than the total number of stops that constitute a route) will be\n",
    "  ignored.\n",
    "  \"\"\"\n",
    "  global valid_trip_count\n",
    "  global invalid_trip_count\n",
    "  global pseudo_invalid_trip_count\n",
    "  global trips_with_no_warnings\n",
    "\n",
    "  trip_list = []\n",
    "  # print('stop_times: {}'.format(stop_times))\n",
    "\n",
    "  terminal_stop_id = route_stops[\n",
    "    route_stops['is_terminal'] == True]['stop_id'].squeeze()\n",
    "  # print('terminal_stop_id: {}'.format(terminal_stop_id))\n",
    "\n",
    "  # assume that the stop_times have been sorted by arrived_at then departed_at\n",
    "  terminal_stop_indices = stop_times[\n",
    "    stop_times['stop_id'] == terminal_stop_id].index.values\n",
    "  # print('terminal_stop_indices: {}'.format(terminal_stop_indices))\n",
    "\n",
    "  northbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'N']['stop_id'].values\n",
    "  northbound_stop_ids = northbound_stop_ids.astype(np.uint32)\n",
    "  # print('northbound_stop_ids: {}'.format(northbound_stop_ids))\n",
    "\n",
    "  southbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'S']['stop_id'].values\n",
    "  southbound_stop_ids = southbound_stop_ids.astype(np.uint32)\n",
    "  # print('southbound_stop_ids: {}'.format(southbound_stop_ids))\n",
    "\n",
    "  def is_northbound(stop_id):\n",
    "    # print('n_stop_id: {}'.format(stop_id))\n",
    "    return True if stop_id in northbound_stop_ids else False\n",
    "\n",
    "  def is_southbound(stop_id):\n",
    "    # print('s_stop_id: {}'.format(southbound_stop_ids))\n",
    "    return True if stop_id in southbound_stop_ids else False\n",
    "\n",
    "  # for i in range(len(terminal_stop_indices)):\n",
    "  for i in [-1] + list(range(len(terminal_stop_indices))):\n",
    "    # treat any stops preceding the first terminal as a partial trip\n",
    "    if i == -1:\n",
    "      try:\n",
    "        round_trip_stop_times = \\\n",
    "          stop_times.loc[stop_times.index.values[0]:terminal_stop_indices[0]]\n",
    "        # print('{} stop times found before first terminal'.format(\n",
    "        #   round_trip_stop_times.shape[0]))\n",
    "      except:\n",
    "        continue\n",
    "    # since the last trip may not end at the terminal, grab all stops after\n",
    "    # the last terminal. If the last trip truly did end at the terminal, the\n",
    "    # below code should branch out appropriately\n",
    "    elif i == len(terminal_stop_indices) - 1:\n",
    "      try:\n",
    "        round_trip_stop_times = \\\n",
    "          stop_times.loc[terminal_stop_indices[i]:stop_times.index.values[-1]]\n",
    "        # print('{} stop times found after last terminal'.format(\n",
    "        #   round_trip_stop_times.shape[0]))\n",
    "      except:\n",
    "        continue\n",
    "    else:\n",
    "      round_trip_stop_times = \\\n",
    "        stop_times.loc[terminal_stop_indices[i]:terminal_stop_indices[i+1]]\n",
    "      # print('round_trip_stop_times_range: ({}, {})'.format(\n",
    "      #   terminal_stop_indices[i], terminal_stop_indices[i+1]))\n",
    "\n",
    "    # ignore ranges that are less than 3 stops long as these are probably\n",
    "    # sequences of multiple records representing a single event\n",
    "    if 2 <= round_trip_stop_times.shape[0]:  # <= route_stops.shape[0] * 1:#\n",
    "      #confirm that the sequence of trips divides cleanly across the two bounds\n",
    "      are_northbound = round_trip_stop_times['stop_id'].apply(is_northbound)\n",
    "      # print('are_northbound: {}'.format(are_northbound.values))\n",
    "\n",
    "      are_southbound = round_trip_stop_times['stop_id'].apply(is_southbound)\n",
    "      # print('are_southbound: {}'.format(are_southbound.values))\n",
    "\n",
    "      are_equal = are_northbound == are_southbound\n",
    "      # print('are_equal: {}'.format(are_equal.values))\n",
    "\n",
    "      if not are_equal.any():\n",
    "        # ignore the 0th stop since the southbound terminal may precede an entire\n",
    "        # northbound trip or vice versa, making a bound appear not uniform\n",
    "        northbound_indices = are_northbound.iloc[1:-1][\n",
    "          are_northbound.iloc[1:-1] == True].index\n",
    "        # print('northbound_indices:\\n{}'.format(northbound_indices))\n",
    "        southbound_indices = are_southbound.iloc[1:-1][\n",
    "          are_southbound.iloc[1:-1] == True].index\n",
    "        # print('southbound_indices:\\n{}'.format(southbound_indices))\n",
    "        # assume argwhere will preserve the index ordering\n",
    "        if northbound_indices.shape[0] > 2 and southbound_indices.shape[0] > 2:\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          valid_trip_count += 2\n",
    "          # in this round trip, the northbound trip precedes the southbound trip\n",
    "          # if northbound_indices[-1] < southbound_indices[0]:\n",
    "          if np.all(northbound_indices < southbound_indices[0]) \\\n",
    "              and np.all(northbound_indices[-1] < southbound_indices):\n",
    "            # the southbound trip\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.loc[\n",
    "              northbound_indices[-1]]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "              northbound_indices.shape[0]))\n",
    "\n",
    "            start_time = round_trip_stop_times.loc[\n",
    "              northbound_indices[-1]]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "              southbound_indices.shape[0]))\n",
    "          # elif northbound_indices[0] > southbound_indices[-1]:\n",
    "          elif np.all(northbound_indices[0] > southbound_indices) \\\n",
    "              and np.all(northbound_indices > southbound_indices[-1]):\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.loc[\n",
    "              southbound_indices[-1]]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "              southbound_indices.shape[0]))\n",
    "\n",
    "            start_time = round_trip_stop_times.loc[\n",
    "              southbound_indices[-1]]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "              northbound_indices.shape[0]))\n",
    "        elif southbound_indices.shape[0] >= 2 \\\n",
    "            and northbound_indices.shape[0] == 0:\n",
    "          valid_trip_count += 1\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          trip_list.append(Trip(\n",
    "            route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "            southbound_indices.shape[0]))\n",
    "        elif southbound_indices.shape[0] == 0 \\\n",
    "            and northbound_indices.shape[0] >= 2:\n",
    "          valid_trip_count += 1\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          trip_list.append(Trip(\n",
    "            route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "            northbound_indices.shape[0]))\n",
    "        else:\n",
    "          pseudo_invalid_trip_count += 1\n",
    "      else:\n",
    "        invalid_trip_count += 1\n",
    "  return trip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_warnings_to_trips(\n",
    "  route_stop_df, stop_time_df, vehicle_assignment_df, warning_df):\n",
    "  \"\"\"\n",
    "  Given four pandas data frames representing warning events, route stops,\n",
    "  stop events and driver schedules, construct a list of individual route trips,\n",
    "  assign warning events that occurred during each trip to that trip, then return\n",
    "  the complete list.\n",
    "  \"\"\"\n",
    "  global trips_with_no_warnings\n",
    "\n",
    "  global_trip_list = []\n",
    "  # print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "  # stop_time_df.sort_values(['arrived_at', 'departed_at'], inplace=True)\n",
    "  # stop_time_df.set_index(pd.RangeIndex(stop_time_df.shape[0]), inplace=True)\n",
    "\n",
    "  relevant_route_ids = stop_time_df['route_id'].unique()\n",
    "  print('route ids among stop times: {}'.format(relevant_route_ids))\n",
    "  # since DASH A routes are not in teh DB yet...\n",
    "  available_route_ids = route_stop_df['route_id'].unique()\n",
    "  print('route ids among route stops: {}'.format(available_route_ids))\n",
    "\n",
    "  for route_id in relevant_route_ids:\n",
    "    if route_id in available_route_ids:\n",
    "      # collect all driver assignments for the given route for all time\n",
    "      vehicles_that_ran_route = vehicle_assignment_df[\n",
    "        vehicle_assignment_df['route_id'] == route_id]\n",
    "      # print('relevant_vehicle_assignments:\\n{}'.format(relevant_vehicle_assignments))\n",
    "\n",
    "      # identify unique set of vehicle ids for all time\n",
    "      unique_vehicle_ids = vehicles_that_ran_route['vehicle_id'].unique()\n",
    "      # print('unique_vehicle_ids:\\n{}  '.format(unique_vehicle_ids))\n",
    "\n",
    "      for vehicle_id in unique_vehicle_ids:\n",
    "        relevant_vehicle_assignments = vehicles_that_ran_route[\n",
    "          vehicles_that_ran_route['vehicle_id'] == vehicle_id]\n",
    "\n",
    "        relevant_driver_ids = relevant_vehicle_assignments['driver_id'].unique()\n",
    "\n",
    "        for driver_id in relevant_driver_ids:\n",
    "          driver_assignments = relevant_vehicle_assignments[\n",
    "            relevant_vehicle_assignments['driver_id'] == driver_id]\n",
    "\n",
    "          for i in range(driver_assignments.shape[0]):\n",
    "            driver_start_time = driver_assignments.iloc[i].start_time\n",
    "            driver_end_time = driver_assignments.iloc[i].end_time\n",
    "\n",
    "            # here we assume that any bus on the given route for the given\n",
    "            # driver during a given trip (of multiple trips) will not switch to\n",
    "            # a different route and then switch back.\n",
    "\n",
    "            # although it is possible for some stops to be included that follow\n",
    "            # the driver's trip start time but precede the route's initial stop,\n",
    "            # warnings during that interval will be ignored and only those\n",
    "            # occurring after the first stop departure will be included\n",
    "            driver_stop_times = stop_time_df.query(\n",
    "              'route_id == @route_id & '\n",
    "              'vehicle_id == @vehicle_id & '\n",
    "              'departed_at >= @driver_start_time & '\n",
    "              'arrived_at < @driver_end_time')\n",
    "\n",
    "            driver_stop_times = driver_stop_times.sort_values(\n",
    "              ['arrived_at', 'departed_at'])\n",
    "\n",
    "            driver_stop_times.set_index(\n",
    "              pd.RangeIndex(driver_stop_times.shape[0]), inplace=True)\n",
    "\n",
    "            # print('route: {}, vehicle: {}, driver: {}, start_time: {}, '\n",
    "            #       'end_time: {}'.format(route_id, vehicle_id, driver_id,\n",
    "            #                             driver_start_time, driver_end_time))\n",
    "\n",
    "            # print('route: {}, vehicle: {}, driver: {}, start_time: {}, '\n",
    "            #       'end_time: {}, stops:\\n{}'.format(\n",
    "            #   route_id, vehicle_id, driver_id, driver_start_time,\n",
    "            #   driver_end_time, driver_stop_times.describe()))\n",
    "\n",
    "            # collect set of stops for the given route\n",
    "            route_stops = route_stop_df[route_stop_df['route_id'] == route_id]\n",
    "            route_stops = route_stops.sort_values(['heading', 'sequence'])\n",
    "            route_stops.set_index(pd.RangeIndex(route_stops.shape[0]),\n",
    "                                  inplace=True)\n",
    "            # print('route {} stops:\\n{}'.format(route_id, route_stops.describe()))\n",
    "\n",
    "            route_trip_list = construct_trip_list(route_stops, driver_stop_times)\n",
    "            # print('found {} route trips'.format(len(route_trip_list)))\n",
    "\n",
    "            # assume that warning and stop_time records have seconds in their\n",
    "            # timestamp\n",
    "            for j in range(len(route_trip_list)):\n",
    "              trip = route_trip_list[j]\n",
    "              trip.driver_id = driver_id\n",
    "              trip.bus_number = driver_assignments.iloc[i].bus_number\n",
    "              # print('trip_start_time: {}, trip_end_time: {}'.format(trip_start_time, trip_end_time))\n",
    "\n",
    "              trip_warnings = warning_df.query(\n",
    "                'bus_number == @trip.bus_number & '\n",
    "                'loc_time >= @trip.start_time & '\n",
    "                'loc_time < @trip.end_time')\n",
    "\n",
    "              if trip_warnings.shape[0] == 0:\n",
    "                # print('Trip {} for run {}: {} has no warnings'.format(\n",
    "                #   j, i, [vehicle_id, driver_id, route_id, trip.start_time,\n",
    "                #       trip.end_time, trip.heading, trip.stop_count]))\n",
    "\n",
    "                trips_with_no_warnings += 1\n",
    "              # else:\n",
    "              #   print('Trip {} for {} has warnings'.format(\n",
    "              #     i, [vehicle_id, driver_id, route_id, trip.start_time, trip.end_time, trip.heading]))\n",
    "\n",
    "              warning_assignments = trip_warnings[\n",
    "                ['vehicle_id', 'driver_id', 'route_id']]\n",
    "\n",
    "              # print('pre-assignment: {}'.format(warning_df.loc[trip_warnings.index]))\n",
    "              # warning_df['vehicle_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   vehicle_id, trip_warnings.shape[0])\n",
    "              # warning_df['driver_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   driver_id, trip_warnings.shape[0])\n",
    "              # warning_df['route_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   route_id, trip_warnings.shape[0])\n",
    "              # print('post-assignment: {}'.format(warning_df.loc[trip_warnings.index]))\n",
    "\n",
    "              # print('pre-assignment: {}'.format(trip_warnings.head(1)))\n",
    "              trip_warnings.loc[:, 'vehicle_id'] = np.tile(\n",
    "                vehicle_id, trip_warnings.shape[0])\n",
    "              trip_warnings.loc[:, 'driver_id'] = np.tile(\n",
    "                driver_id, trip_warnings.shape[0])\n",
    "              trip_warnings.loc[:, 'route_id'] = np.tile(\n",
    "                route_id, trip_warnings.shape[0])\n",
    "              # print('post-assignment: {}'.format(trip_warnings.head(1)))\n",
    "\n",
    "              # if not np.all(warning_assignments.values == 0):\n",
    "              #   print('Assigning some warnings to trip\\n{}: {}\\nthat have '\n",
    "              #         'already been assigned to\\n{}'.format(i, [\n",
    "              #     vehicle_id, driver_id, route_id, trip.start_time,\n",
    "              #     trip.end_time, trip.heading], warning_assignments))\n",
    "\n",
    "              trip.warnings = trip_warnings\n",
    "              # what if we use only arrive_at to define both the start and end\n",
    "              # of a trip, and then split warnings using > and <= at trip joints\n",
    "\n",
    "              # print('trip warnings: {}'.format(trip.warnings))\n",
    "\n",
    "            global_trip_list.extend(route_trip_list)\n",
    "    else:\n",
    "      print('missing definition for route with id {}'.format(route_id))\n",
    "\n",
    "  print('valid_trip_count: {}'.format(valid_trip_count))\n",
    "  print('invalid_trip_count: {}'.format(invalid_trip_count))\n",
    "  print('pseudo_invalid_trip_count: {}'.format(pseudo_invalid_trip_count))\n",
    "  print('trips_with_no_warnings: {}'.format(trips_with_no_warnings))\n",
    "  # TODO: handle unassigned warnings\n",
    "  return global_trip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_longitudinal_data_product(trip_list):\n",
    "  \"\"\"Given a list of Trip objects with warnings assigned, create longitudinal\n",
    "  records and return them as a numpy array \"\"\"\n",
    "  output_data = np.ndarray((len(trip_list),), dtype=longitudinal_type)\n",
    "\n",
    "  # trip being aggregated\n",
    "  for i in range(len(trip_list)):\n",
    "    trip = trip_list[i]\n",
    "\n",
    "    trip_data = np.array([[\n",
    "      trip.route_name, trip.route_id, trip.heading, trip.driver_id, trip.vehicle_id,\n",
    "      trip.bus_number, trip.start_time, trip.end_time]])\n",
    "\n",
    "    unique_warnings, counts = np.unique(\n",
    "      trip.warnings.loc[:, 'warning_name'].values, return_counts=True)\n",
    "\n",
    "    warning_data = np.zeros((1, warnings_header.shape[0]))\n",
    "\n",
    "    for j in range(unique_warnings.shape[0]):\n",
    "      index = np.nonzero(warnings_header == unique_warnings[j])\n",
    "\n",
    "      if len(index) > 0:\n",
    "        assert len(index) == 1\n",
    "        warning_data[0, index] = counts[j]\n",
    "\n",
    "    trip_data = np.squeeze(np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "    output_data[i] = tuple(trip_data)\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data\n",
    "\n",
    "\n",
    "def construct_hotspot_data_product(trip_list):\n",
    "  output_data = np.ndarray(\n",
    "    (sum([trip.warnings.shape[0] for trip in trip_list]),), dtype=hotspot_type)\n",
    "\n",
    "  index = 0\n",
    "\n",
    "  for trip in trip_list:\n",
    "    if trip.warnings.shape[0] > 0:\n",
    "      warning_data = trip.warnings.loc[:, ['loc_time', 'warning_name',\n",
    "                                          'latitude', 'longitude']].values\n",
    "\n",
    "      trip_data = np.tile([\n",
    "        trip.route_name, trip.route_id, trip.heading, trip.driver_id,\n",
    "        trip.vehicle_id, trip.bus_number], (warning_data.shape[0], 1))\n",
    "\n",
    "      output_data[index:index + warning_data.shape[0]] = np.apply_along_axis(\n",
    "        to_tuple, 1, np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "      index += warning_data.shape[0]\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also identify duplicates when a record is dropped for the second time\n",
    "def identify_unassigned_warnings(trip_list, warning_df):\n",
    "  \"\"\"use the indices of warning data frames assigned to trips to identify\n",
    "  warnings in warning_df that are not assigned to any trip, \"\"\"\n",
    "  w = warning_df.copy()\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for trip in trip_list:\n",
    "    try:\n",
    "      w = w.drop(trip.warnings.index)\n",
    "    except ValueError as ve:\n",
    "      print('1. {}'.format(ve))\n",
    "      try:\n",
    "        w = w.drop(list(set(\n",
    "          warning_df.index.values).intersection(trip.warnings.index.values)))\n",
    "      except Exception as e:\n",
    "        print('2. {}'.format(e))\n",
    "      # pass\n",
    "\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for i in range(0, w.shape[0], 10000):\n",
    "    print(w.iloc[i])\n",
    "\n",
    "  print('final w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converted from .py to arguments above\n",
    "```\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument('--db_path', default='ituran_synchromatics_data.sqlite')\n",
    "  parser.add_argument('--route_stop_table_name', default='route_stop')\n",
    "  parser.add_argument('--stop_event_table_name', default='stop_time')\n",
    "  parser.add_argument('--driver_schedule_table_name',\n",
    "                      default='vehicle_assignment')\n",
    "  parser.add_argument('--warning_table_name', default='warning')\n",
    "  parser.add_argument('--hotspot_record_table_name',\n",
    "                      default='hotspot_data_product')\n",
    "  parser.add_argument('--longitudinal_record_table_name',\n",
    "                      default='longitudinal_data_product')\n",
    "  parser.add_argument('--if_exists', default='append')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start batching over months\n",
    "\n",
    "The next several steps work across entire time frame, but at warning_ext and trip_list, fails. Try to split these next by month and stitch together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = ['01/01/2018 00:00:00', '02/01/2018 00:00:00', '03/01/2018 00:00:00', '04/01/2018 00:00:00', '05/01/2018 00:00:00', '06/01/2018 00:00:00', \n",
    "          '07/01/2018 00:00:00', '08/01/2018 00:00:00', '09/01/2018 00:00:00', '10/01/2018 00:00:00', '11/01/2018 00:00:00', '12/01/2018 00:00:00']\n",
    "stops = ['01/31/2018 23:59:59', '02/28/2018 23:59:59', '03/31/2018 23:59:59', '04/30/2018 23:59:59', '05/31/2018 23:59:59', '06/30/2018 23:59:59', \n",
    "         '07/31/2018 23:59:59', '08/31/2018 23:59:59', '09/30/2018 23:59:59', '10/31/2018 23:59:59', '11/30/2018 23:59:59', '12/31/2018 23:59:59']\n",
    "\n",
    "monthbatch = pd.DataFrame.from_records({'starts': starts, 'stops': stops})\n",
    "\n",
    "# monthbatch = monthbatch.iloc[1:2,] # just select Feb as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "31  2018-08-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "31  2018-08-01 00:00:00\n",
      "32  2018-09-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "31  2018-08-01 00:00:00\n",
      "32  2018-09-01 00:00:00\n",
      "33  2018-10-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "31  2018-08-01 00:00:00\n",
      "32  2018-09-01 00:00:00\n",
      "33  2018-10-01 00:00:00\n",
      "34  2018-11-01 00:00:00\n",
      "['2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00', '2018-01-01 00:00:00', '2018-02-01 00:00:00', '2018-03-01 00:00:00', '2018-04-01 00:00:00', '2018-05-01 00:00:00', '2018-06-01 00:00:00', '2018-07-01 00:00:00', '2018-08-01 00:00:00', '2018-09-01 00:00:00', '2018-10-01 00:00:00', '2018-11-01 00:00:00', '2018-12-01 00:00:00']\n",
      "                   Done\n",
      "0   2018-01-01 00:00:00\n",
      "1   2018-02-01 00:00:00\n",
      "2   2018-03-01 00:00:00\n",
      "3   2018-04-01 00:00:00\n",
      "4   2018-05-01 00:00:00\n",
      "5   2018-06-01 00:00:00\n",
      "6   2018-07-01 00:00:00\n",
      "7   2018-08-01 00:00:00\n",
      "8   2018-09-01 00:00:00\n",
      "9   2018-10-01 00:00:00\n",
      "10  2018-11-01 00:00:00\n",
      "11  2018-12-01 00:00:00\n",
      "12  2018-01-01 00:00:00\n",
      "13  2018-02-01 00:00:00\n",
      "14  2018-03-01 00:00:00\n",
      "15  2018-04-01 00:00:00\n",
      "16  2018-05-01 00:00:00\n",
      "17  2018-06-01 00:00:00\n",
      "18  2018-07-01 00:00:00\n",
      "19  2018-08-01 00:00:00\n",
      "20  2018-09-01 00:00:00\n",
      "21  2018-10-01 00:00:00\n",
      "22  2018-11-01 00:00:00\n",
      "23  2018-12-01 00:00:00\n",
      "24  2018-01-01 00:00:00\n",
      "25  2018-02-01 00:00:00\n",
      "26  2018-03-01 00:00:00\n",
      "27  2018-04-01 00:00:00\n",
      "28  2018-05-01 00:00:00\n",
      "29  2018-06-01 00:00:00\n",
      "30  2018-07-01 00:00:00\n",
      "31  2018-08-01 00:00:00\n",
      "32  2018-09-01 00:00:00\n",
      "33  2018-10-01 00:00:00\n",
      "34  2018-11-01 00:00:00\n",
      "35  2018-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for index, row in monthbatch.iterrows():\n",
    "    start_datetime = datetime.strptime(row['starts'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # Track completed months\n",
    "    #print(start_datetime)\n",
    "    done_months.append(start_datetime)\n",
    "    print(done_months)\n",
    " #   done_months_table = pd.DataFrame.from_records(done_months)\n",
    "    done_months_table = pd.DataFrame(done_months, columns = ['Done'])\n",
    "    \n",
    "    print(done_months_table)\n",
    "    \n",
    "    done_months_table.to_sql('completed_months_deleteme', db, if_exists = 'replace', index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_time_df:\n",
      "            stop_id       route_id     vehicle_id  arrival_latitude  \\\n",
      "count  4.364660e+05  436466.000000  436466.000000     436466.000000   \n",
      "mean   1.060091e+05     339.561773    1264.905140         34.045984   \n",
      "std    1.626878e+05      54.203740     963.228718          0.009984   \n",
      "min    4.219900e+04     296.000000     324.000000         34.018210   \n",
      "25%    9.045300e+04     297.000000     358.000000         34.040637   \n",
      "50%    9.095900e+04     298.000000    1611.000000         34.048285   \n",
      "75%    9.142100e+04     408.000000    1631.000000         34.052886   \n",
      "max    2.294803e+06     409.000000    3809.000000         34.067394   \n",
      "\n",
      "       arrival_longitude  departure_latitude  departure_longitude  \\\n",
      "count      436466.000000       436466.000000        436466.000000   \n",
      "mean         -118.253745           34.046003          -118.253768   \n",
      "std             0.011646            0.009993             0.011677   \n",
      "min          -118.291822           34.018171          -118.291717   \n",
      "25%          -118.259483           34.040461          -118.259212   \n",
      "50%          -118.254265           34.048346          -118.254487   \n",
      "75%          -118.245330           34.052965          -118.245123   \n",
      "max          -118.230944           34.067309          -118.231037   \n",
      "\n",
      "       stop_time_id  \n",
      "count  4.364660e+05  \n",
      "mean   1.565481e+07  \n",
      "std    5.222448e+06  \n",
      "min    9.297589e+06  \n",
      "25%    1.021915e+07  \n",
      "50%    1.716063e+07  \n",
      "75%    2.189660e+07  \n",
      "max    2.221762e+07  \n",
      "vehicle_assignment_df:\n",
      "        vehicle_assignment_id  vehicle_id  route_id  driver_id  start_time  \\\n",
      "count                       0           0         0          0           0   \n",
      "unique                      0           0         0          0           0   \n",
      "\n",
      "        end_time  bus_number  first_name  last_name  badge_number  \n",
      "count          0           0           0          0             0  \n",
      "unique         0           0           0          0             0  \n",
      "warning_df:\n",
      "         bus_number    latitude   longitude\n",
      "count    636.000000  636.000000  636.000000\n",
      "mean   15329.704403   34.047636 -118.253703\n",
      "std        6.935522    0.011626    0.014138\n",
      "min    15301.000000   34.018340 -118.291485\n",
      "25%    15325.000000   34.043320 -118.258396\n",
      "50%    15329.000000   34.049091 -118.250853\n",
      "75%    15340.000000   34.056115 -118.243333\n",
      "max    15340.000000   34.067093 -118.232978\n",
      "warning_df head:\n",
      "                     loc_time  bus_number  \\\n",
      "0  2018-01-29 13:46:09.000000       15322   \n",
      "1  2018-01-29 13:46:46.000000       15322   \n",
      "\n",
      "                                          address  \\\n",
      "0  850-898 N Broadway, Los Angeles, CA 90012, USA   \n",
      "1      900 N Broadway, Los Angeles, CA 90012, USA   \n",
      "\n",
      "                       warning_name   latitude   longitude  vehicle_id  \\\n",
      "0  ME - Pedestrian In Range Warning  34.064026 -118.237463           0   \n",
      "1  ME - Pedestrian In Range Warning  34.064166 -118.237360           0   \n",
      "\n",
      "   driver_id  route_id  \n",
      "0          0         0  \n",
      "1          0         0  \n",
      "route ids among stop times: [296 297 298 408 409]\n",
      "route ids among route stops: [ 296  297 7690  408  409 8435 9212 9270 9736 9960]\n",
      "missing definition for route with id 298\n",
      "valid_trip_count: 0\n",
      "invalid_trip_count: 0\n",
      "pseudo_invalid_trip_count: 0\n",
      "trips_with_no_warnings: 0\n",
      "found 0 total trips\n",
      "       route_id  driver_id  vehicle_id  bus_number  \\\n",
      "count       0.0        0.0         0.0         0.0   \n",
      "mean        NaN        NaN         NaN         NaN   \n",
      "std         NaN        NaN         NaN         NaN   \n",
      "min         NaN        NaN         NaN         NaN   \n",
      "25%         NaN        NaN         NaN         NaN   \n",
      "50%         NaN        NaN         NaN         NaN   \n",
      "75%         NaN        NaN         NaN         NaN   \n",
      "max         NaN        NaN         NaN         NaN   \n",
      "\n",
      "       ME - Pedestrian Collision Warning  ME - Pedestrian In Range Warning  \\\n",
      "count                                0.0                               0.0   \n",
      "mean                                 NaN                               NaN   \n",
      "std                                  NaN                               NaN   \n",
      "min                                  NaN                               NaN   \n",
      "25%                                  NaN                               NaN   \n",
      "50%                                  NaN                               NaN   \n",
      "75%                                  NaN                               NaN   \n",
      "max                                  NaN                               NaN   \n",
      "\n",
      "       PCW-LF  PCW-LR  PCW-RR  PDZ - Left Front  PDZ-LR  PDZ-R  \\\n",
      "count     0.0     0.0     0.0               0.0     0.0    0.0   \n",
      "mean      NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "std       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "min       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "25%       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "50%       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "75%       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "max       NaN     NaN     NaN               NaN     NaN    NaN   \n",
      "\n",
      "       Safety - Braking - Aggressive  Safety - Braking - Dangerous  \n",
      "count                            0.0                           0.0  \n",
      "mean                             NaN                           NaN  \n",
      "std                              NaN                           NaN  \n",
      "min                              NaN                           NaN  \n",
      "25%                              NaN                           NaN  \n",
      "50%                              NaN                           NaN  \n",
      "75%                              NaN                           NaN  \n",
      "max                              NaN                           NaN  \n",
      "       route_id  driver_id  vehicle_id  bus_number  latitude  longitude\n",
      "count       0.0        0.0         0.0         0.0       0.0        0.0\n",
      "mean        NaN        NaN         NaN         NaN       NaN        NaN\n",
      "std         NaN        NaN         NaN         NaN       NaN        NaN\n",
      "min         NaN        NaN         NaN         NaN       NaN        NaN\n",
      "25%         NaN        NaN         NaN         NaN       NaN        NaN\n",
      "50%         NaN        NaN         NaN         NaN       NaN        NaN\n",
      "75%         NaN        NaN         NaN         NaN       NaN        NaN\n",
      "max         NaN        NaN         NaN         NaN       NaN        NaN\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2462766c8c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# Track completed months\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mdone_months\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_datetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mdone_months\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'completed_months'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'append'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_sql'"
     ]
    }
   ],
   "source": [
    "# Iterate over months\n",
    "done_months = [] # track completed months\n",
    "\n",
    "for index, row in monthbatch.iterrows():\n",
    "    \n",
    "    db_path = 'sqlite:///' + path.join(project_root_dir, 'ituran_synchromatics_data.sqlite')\n",
    "\n",
    "    db = create_engine(db_path)\n",
    "\n",
    "    route_stop_df = pd.read_sql_table(route_stop_table_name, db)\n",
    "    # print('route_stop_df:\\n{}'.format(route_stop_df.describe()))\n",
    "\n",
    "    # Allow for a subset of data to be processed based on a date range\n",
    "    start_datetime = datetime.strptime(row['starts'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_datetime = datetime.strptime(row['stops'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        stop_time_df = pd.read_sql(\n",
    "            'select * from {} where arrived_at >= datetime(\\'{}\\') and arrived_at <= '\n",
    "            'datetime(\\'{}\\')'.format(stop_event_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        stop_time_df = pd.read_sql_table(stop_event_table_name, db)\n",
    "\n",
    "    print('stop_time_df:\\n{}'.format(stop_time_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        vehicle_assignment_df = pd.read_sql(\n",
    "            'select * from {} where start_time >= datetime(\\'{}\\') and start_time <= datetime(\\'{}\\')'.format(driver_schedule_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        vehicle_assignment_df = pd.read_sql_table(driver_schedule_table_name, db)\n",
    "\n",
    "    print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        warning_df = pd.read_sql(\n",
    "            'select * from {} where loc_time >= \\'{}\\' and loc_time <= \\'{}\\''.format(warning_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        warning_df = pd.read_sql_table(warning_table_name, db)\n",
    "    \n",
    "    print('warning_df:\\n{}'.format(warning_df.describe()))\n",
    "    \n",
    "    # extend warning df to include columns that uniquely identify trips so that\n",
    "    # warnings assigned to multiple runs can be discovered.\n",
    "    warning_ext = pd.DataFrame(\n",
    "        data=np.zeros((warning_df.shape[0], 3), dtype=np.uint32),\n",
    "        columns=['vehicle_id', 'driver_id', 'route_id'], index=warning_df.index)\n",
    "\n",
    "    warning_df = pd.concat([warning_df, warning_ext], axis=1)\n",
    "\n",
    "    print('warning_df head:\\n{}'.format(warning_df.head(2)))\n",
    "    \n",
    "    trip_list = assign_warnings_to_trips(\n",
    "        route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\n",
    "    \n",
    "    print('found {} total trips'.format(len(trip_list)))\n",
    "\n",
    "    longitudinal_data = construct_longitudinal_data_product(trip_list)\n",
    "    \n",
    "    longitudinal_data.to_sql(\n",
    "        longitudinal_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "\n",
    "    print(longitudinal_data.describe())\n",
    "\n",
    "    hotspot_data = construct_hotspot_data_product(trip_list)\n",
    "    hotspot_data.to_sql(\n",
    "        hotspot_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "    print(hotspot_data.describe())\n",
    "    \n",
    "    # Track completed months\n",
    "    done_months.append(start_datetime)\n",
    "    print(done_months)\n",
    "    done_months_table = pd.DataFrame(done_months, columns = ['Done'])  \n",
    "    done_months_table.to_sql('completed_months', db, if_exists = 'replace', index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
