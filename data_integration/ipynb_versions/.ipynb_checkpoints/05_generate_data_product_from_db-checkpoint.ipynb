{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate products\n",
    "\n",
    "Follows Step 4, `04_add_stop_times_to_db.ipynb`\n",
    "\n",
    "**In process for `ituran_synchromatics_data.sqlite` in Data Integration - All Months**\n",
    "\n",
    "This script creates or replaces a table in the database at the supplied\n",
    "path that contains the set of stops for each of five Downtown DASH routes\n",
    "\n",
    "This script creates or replaces two tables in the database at the supplied\n",
    "path that contain 'clean' subsets of LADOT DASH trip data, where a clean trip is\n",
    "defined as having a pair of 'terminal' stops with a sequence of all northbound\n",
    "stops followed by all southbound stops (or vice versa) in between, and having\n",
    "a number of stop events no greater than the total number of stops that\n",
    "constitute a round trip on the route. A terminal stop is a stop where drivers\n",
    "transition their shifts.\n",
    "\n",
    "TODO: resolve issues that prevent all stop events from being included in the\n",
    "data product, e.g. when buses return to a depo from a stop other than the\n",
    "terminal, or when a driver running multiple contiguous rounds trips in a\n",
    "single shift does not stop at the terminal between two bounds.\n",
    "\n",
    "The hotspot_data_product table contains per-warning records for the purpose of\n",
    "hotspot analysis and the longitudinal_data_product table contains per-trip\n",
    "records, with warnings aggegated into counts for the purpose of longitudinal\n",
    "analysis.\n",
    "\n",
    "Data product construction is performed in three phases. First, individual trips\n",
    "are identified in construct_trip_list(), then corresponding warnings are\n",
    "assigned to each trip based on a time range and a vehicle id in\n",
    "assign_warnings_to_trips(), and finally either a hotspot or a longitudinal data\n",
    "product is constructed given the trips and their warnings in\n",
    "construct_hotspot_data_product() or construct_longitudinal_data_product()\n",
    "\n",
    "TODO: log print statements\n",
    "TODO: only db read stop events in the date range across driver schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunk by month and multiprocess**\n",
    "\n",
    "In process. Idea now (2019-04-01) is to split the job into tasks by month, then use `multiprocessing` to process multiple month at a time. \n",
    "\n",
    "Start with batching by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted from parser, adding project root dir\n",
    "project_root_dir = r'\\\\vntscex.local\\DFS\\3BC-Share$_Mobileye_Data\\Data\\Data Integration - All Months' \n",
    "\n",
    "db_path='ituran_synchromatics_data.sqlite'\n",
    "route_stop_table_name='route_stop'\n",
    "stop_event_table_name='stop_time'\n",
    "driver_schedule_table_name='vehicle_assignment'\n",
    "warning_table_name='warning'\n",
    "hotspot_record_table_name='hotspot_data_product'\n",
    "longitudinal_record_table_name='longitudinal_data_product'\n",
    "if_exists='append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define hostpot table column names and a custom data type fo organizing data\n",
    "# into records\n",
    "hotspot_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'loc_time', 'warning_name', 'latitude', 'longitude'])\n",
    "\n",
    "hotspot_type = np.dtype([\n",
    "  (hotspot_header[0], np.unicode_, 6), (hotspot_header[1], np.uint32),\n",
    "  (hotspot_header[2], np.unicode_, 10), (hotspot_header[3], np.uint32),\n",
    "  (hotspot_header[4], np.uint32), (hotspot_header[5], np.uint32),\n",
    "  (hotspot_header[6], datetime), (hotspot_header[7], np.unicode_, 34),\n",
    "  (hotspot_header[8], np.float64), (hotspot_header[9], np.float64)])\n",
    "\n",
    "# define longitudinal table column names and a custom data type fo organizing\n",
    "# data into records\n",
    "longitudinal_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'start_time', 'end_time', 'ME - Pedestrian Collision Warning',\n",
    "  'ME - Pedestrian In Range Warning', 'PCW-LF', 'PCW-LR', 'PCW-RR',\n",
    "  'PDZ - Left Front', 'PDZ-LR', 'PDZ-R', 'Safety - Braking - Aggressive',\n",
    "  'Safety - Braking - Dangerous'])\n",
    "\n",
    "longitudinal_type = np.dtype([\n",
    "  (longitudinal_header[0], np.unicode_, 6), (longitudinal_header[1], np.uint32),\n",
    "  (longitudinal_header[2], np.unicode_, 10), (longitudinal_header[3], np.uint32),\n",
    "  (longitudinal_header[4], np.uint32), (longitudinal_header[5], np.uint32),\n",
    "  (longitudinal_header[6], datetime),\n",
    "  (longitudinal_header[7], datetime), (longitudinal_header[8], np.uint16),\n",
    "  (longitudinal_header[9], np.uint16), (longitudinal_header[10], np.uint16),\n",
    "  (longitudinal_header[11], np.uint16), (longitudinal_header[12], np.uint16),\n",
    "  (longitudinal_header[13], np.uint16), (longitudinal_header[14], np.uint16),\n",
    "  (longitudinal_header[15], np.uint16), (longitudinal_header[16], np.uint16),\n",
    "  (longitudinal_header[17], np.uint16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a separate collection of warning headers will be used to first create warning\n",
    "# count data before concatenating them with trip data to form longitudinal\n",
    "# records\n",
    "warnings_header = longitudinal_header[8:]\n",
    "\n",
    "valid_trip_count = 0\n",
    "invalid_trip_count = 0\n",
    "pseudo_invalid_trip_count = 0\n",
    "trips_with_no_warnings = 0\n",
    "\n",
    "# a Run object is used to organize an individual trip's properties together with\n",
    "# a collection of warnings that may vary in length from trip to trip\n",
    "class Trip:\n",
    "  def __init__(self, route_name, route_id, heading, vehicle_id, start_time,\n",
    "               end_time, stop_count, driver_id=None, bus_number=None, warnings=None):\n",
    "    self.route_name = route_name\n",
    "    self.route_id = route_id\n",
    "    self.heading = heading\n",
    "    self.vehicle_id = vehicle_id\n",
    "    self.start_time = start_time\n",
    "    self.end_time = end_time\n",
    "    self.driver_id = driver_id\n",
    "    self.bus_number = bus_number\n",
    "    self.warnings = warnings\n",
    "    self.stop_count = stop_count\n",
    "\n",
    "\n",
    "# numpy arrays of custom dtype expect elements to be tuples. Because\n",
    "# longitudinal records are created in batches, organization of data into a tuple\n",
    "# must be applied row-wise across the batch dimension\n",
    "def to_tuple(element):\n",
    "  return np.array(tuple(element), dtype=hotspot_type)\n",
    "\n",
    "\n",
    "def construct_trip_list(route_stops, stop_times):\n",
    "  \"\"\"\n",
    "  Given a time-ordered sequence of stops a bus traveled to or past, and the\n",
    "  arrival time for each stop, extract instances of round trips (between the\n",
    "  departure from a terminal to the arrival at that same stop. Records for which\n",
    "  consecutive terminal stops have an unreasonable number of intermediate stops\n",
    "  (e.g. more than the total number of stops that constitute a route) will be\n",
    "  ignored.\n",
    "  \"\"\"\n",
    "  global valid_trip_count\n",
    "  global invalid_trip_count\n",
    "  global pseudo_invalid_trip_count\n",
    "  global trips_with_no_warnings\n",
    "\n",
    "  trip_list = []\n",
    "  # print('stop_times: {}'.format(stop_times))\n",
    "\n",
    "  terminal_stop_id = route_stops[\n",
    "    route_stops['is_terminal'] == True]['stop_id'].squeeze()\n",
    "  # print('terminal_stop_id: {}'.format(terminal_stop_id))\n",
    "\n",
    "  # assume that the stop_times have been sorted by arrived_at then departed_at\n",
    "  terminal_stop_indices = stop_times[\n",
    "    stop_times['stop_id'] == terminal_stop_id].index.values\n",
    "  # print('terminal_stop_indices: {}'.format(terminal_stop_indices))\n",
    "\n",
    "  northbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'N']['stop_id'].values\n",
    "  northbound_stop_ids = northbound_stop_ids.astype(np.uint32)\n",
    "  # print('northbound_stop_ids: {}'.format(northbound_stop_ids))\n",
    "\n",
    "  southbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'S']['stop_id'].values\n",
    "  southbound_stop_ids = southbound_stop_ids.astype(np.uint32)\n",
    "  # print('southbound_stop_ids: {}'.format(southbound_stop_ids))\n",
    "\n",
    "  def is_northbound(stop_id):\n",
    "    # print('n_stop_id: {}'.format(stop_id))\n",
    "    return True if stop_id in northbound_stop_ids else False\n",
    "\n",
    "  def is_southbound(stop_id):\n",
    "    # print('s_stop_id: {}'.format(southbound_stop_ids))\n",
    "    return True if stop_id in southbound_stop_ids else False\n",
    "\n",
    "  # for i in range(len(terminal_stop_indices)):\n",
    "  for i in [-1] + list(range(len(terminal_stop_indices))):\n",
    "    # treat any stops preceding the first terminal as a partial trip\n",
    "    if i == -1:\n",
    "      try:\n",
    "        round_trip_stop_times = \\\n",
    "          stop_times.loc[stop_times.index.values[0]:terminal_stop_indices[0]]\n",
    "        # print('{} stop times found before first terminal'.format(\n",
    "        #   round_trip_stop_times.shape[0]))\n",
    "      except:\n",
    "        continue\n",
    "    # since the last trip may not end at the terminal, grab all stops after\n",
    "    # the last terminal. If the last trip truly did end at the terminal, the\n",
    "    # below code should branch out appropriately\n",
    "    elif i == len(terminal_stop_indices) - 1:\n",
    "      try:\n",
    "        round_trip_stop_times = \\\n",
    "          stop_times.loc[terminal_stop_indices[i]:stop_times.index.values[-1]]\n",
    "        # print('{} stop times found after last terminal'.format(\n",
    "        #   round_trip_stop_times.shape[0]))\n",
    "      except:\n",
    "        continue\n",
    "    else:\n",
    "      round_trip_stop_times = \\\n",
    "        stop_times.loc[terminal_stop_indices[i]:terminal_stop_indices[i+1]]\n",
    "      # print('round_trip_stop_times_range: ({}, {})'.format(\n",
    "      #   terminal_stop_indices[i], terminal_stop_indices[i+1]))\n",
    "\n",
    "    # ignore ranges that are less than 3 stops long as these are probably\n",
    "    # sequences of multiple records representing a single event\n",
    "    if 2 <= round_trip_stop_times.shape[0]:  # <= route_stops.shape[0] * 1:#\n",
    "      #confirm that the sequence of trips divides cleanly across the two bounds\n",
    "      are_northbound = round_trip_stop_times['stop_id'].apply(is_northbound)\n",
    "      # print('are_northbound: {}'.format(are_northbound.values))\n",
    "\n",
    "      are_southbound = round_trip_stop_times['stop_id'].apply(is_southbound)\n",
    "      # print('are_southbound: {}'.format(are_southbound.values))\n",
    "\n",
    "      are_equal = are_northbound == are_southbound\n",
    "      # print('are_equal: {}'.format(are_equal.values))\n",
    "\n",
    "      if not are_equal.any():\n",
    "        # ignore the 0th stop since the southbound terminal may precede an entire\n",
    "        # northbound trip or vice versa, making a bound appear not uniform\n",
    "        northbound_indices = are_northbound.iloc[1:-1][\n",
    "          are_northbound.iloc[1:-1] == True].index\n",
    "        # print('northbound_indices:\\n{}'.format(northbound_indices))\n",
    "        southbound_indices = are_southbound.iloc[1:-1][\n",
    "          are_southbound.iloc[1:-1] == True].index\n",
    "        # print('southbound_indices:\\n{}'.format(southbound_indices))\n",
    "        # assume argwhere will preserve the index ordering\n",
    "        if northbound_indices.shape[0] > 2 and southbound_indices.shape[0] > 2:\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          valid_trip_count += 2\n",
    "          # in this round trip, the northbound trip precedes the southbound trip\n",
    "          # if northbound_indices[-1] < southbound_indices[0]:\n",
    "          if np.all(northbound_indices < southbound_indices[0]) \\\n",
    "              and np.all(northbound_indices[-1] < southbound_indices):\n",
    "            # the southbound trip\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.loc[\n",
    "              northbound_indices[-1]]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "              northbound_indices.shape[0]))\n",
    "\n",
    "            start_time = round_trip_stop_times.loc[\n",
    "              northbound_indices[-1]]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "              southbound_indices.shape[0]))\n",
    "          # elif northbound_indices[0] > southbound_indices[-1]:\n",
    "          elif np.all(northbound_indices[0] > southbound_indices) \\\n",
    "              and np.all(northbound_indices > southbound_indices[-1]):\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.loc[\n",
    "              southbound_indices[-1]]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "              southbound_indices.shape[0]))\n",
    "\n",
    "            start_time = round_trip_stop_times.loc[\n",
    "              southbound_indices[-1]]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            trip_list.append(Trip(\n",
    "              route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "              northbound_indices.shape[0]))\n",
    "        elif southbound_indices.shape[0] >= 2 \\\n",
    "            and northbound_indices.shape[0] == 0:\n",
    "          valid_trip_count += 1\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          trip_list.append(Trip(\n",
    "            route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "            southbound_indices.shape[0]))\n",
    "        elif southbound_indices.shape[0] == 0 \\\n",
    "            and northbound_indices.shape[0] >= 2:\n",
    "          valid_trip_count += 1\n",
    "          route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "          route_name = route_stops.iloc[0]['route_name']\n",
    "          vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          trip_list.append(Trip(\n",
    "            route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "            northbound_indices.shape[0]))\n",
    "        else:\n",
    "          pseudo_invalid_trip_count += 1\n",
    "      else:\n",
    "        invalid_trip_count += 1\n",
    "  return trip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_warnings_to_trips(\n",
    "  route_stop_df, stop_time_df, vehicle_assignment_df, warning_df):\n",
    "  \"\"\"\n",
    "  Given four pandas data frames representing warning events, route stops,\n",
    "  stop events and driver schedules, construct a list of individual route trips,\n",
    "  assign warning events that occurred during each trip to that trip, then return\n",
    "  the complete list.\n",
    "  \"\"\"\n",
    "  global trips_with_no_warnings\n",
    "\n",
    "  global_trip_list = []\n",
    "  # print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "  # stop_time_df.sort_values(['arrived_at', 'departed_at'], inplace=True)\n",
    "  # stop_time_df.set_index(pd.RangeIndex(stop_time_df.shape[0]), inplace=True)\n",
    "\n",
    "  relevant_route_ids = stop_time_df['route_id'].unique()\n",
    "  print('route ids among stop times: {}'.format(relevant_route_ids))\n",
    "  # since DASH A routes are not in teh DB yet...\n",
    "  available_route_ids = route_stop_df['route_id'].unique()\n",
    "  print('route ids among route stops: {}'.format(available_route_ids))\n",
    "\n",
    "  for route_id in relevant_route_ids:\n",
    "    if route_id in available_route_ids:\n",
    "      # collect all driver assignments for the given route for all time\n",
    "      vehicles_that_ran_route = vehicle_assignment_df[\n",
    "        vehicle_assignment_df['route_id'] == route_id]\n",
    "      # print('relevant_vehicle_assignments:\\n{}'.format(relevant_vehicle_assignments))\n",
    "\n",
    "      # identify unique set of vehicle ids for all time\n",
    "      unique_vehicle_ids = vehicles_that_ran_route['vehicle_id'].unique()\n",
    "      # print('unique_vehicle_ids:\\n{}  '.format(unique_vehicle_ids))\n",
    "\n",
    "      for vehicle_id in unique_vehicle_ids:\n",
    "        relevant_vehicle_assignments = vehicles_that_ran_route[\n",
    "          vehicles_that_ran_route['vehicle_id'] == vehicle_id]\n",
    "\n",
    "        relevant_driver_ids = relevant_vehicle_assignments['driver_id'].unique()\n",
    "\n",
    "        for driver_id in relevant_driver_ids:\n",
    "          driver_assignments = relevant_vehicle_assignments[\n",
    "            relevant_vehicle_assignments['driver_id'] == driver_id]\n",
    "\n",
    "          for i in range(driver_assignments.shape[0]):\n",
    "            driver_start_time = driver_assignments.iloc[i].start_time\n",
    "            driver_end_time = driver_assignments.iloc[i].end_time\n",
    "\n",
    "            # here we assume that any bus on the given route for the given\n",
    "            # driver during a given trip (of multiple trips) will not switch to\n",
    "            # a different route and then switch back.\n",
    "\n",
    "            # although it is possible for some stops to be included that follow\n",
    "            # the driver's trip start time but precede the route's initial stop,\n",
    "            # warnings during that interval will be ignored and only those\n",
    "            # occurring after the first stop departure will be included\n",
    "            driver_stop_times = stop_time_df.query(\n",
    "              'route_id == @route_id & '\n",
    "              'vehicle_id == @vehicle_id & '\n",
    "              'departed_at >= @driver_start_time & '\n",
    "              'arrived_at < @driver_end_time')\n",
    "\n",
    "            driver_stop_times = driver_stop_times.sort_values(\n",
    "              ['arrived_at', 'departed_at'])\n",
    "\n",
    "            driver_stop_times.set_index(\n",
    "              pd.RangeIndex(driver_stop_times.shape[0]), inplace=True)\n",
    "\n",
    "            # print('route: {}, vehicle: {}, driver: {}, start_time: {}, '\n",
    "            #       'end_time: {}'.format(route_id, vehicle_id, driver_id,\n",
    "            #                             driver_start_time, driver_end_time))\n",
    "\n",
    "            # print('route: {}, vehicle: {}, driver: {}, start_time: {}, '\n",
    "            #       'end_time: {}, stops:\\n{}'.format(\n",
    "            #   route_id, vehicle_id, driver_id, driver_start_time,\n",
    "            #   driver_end_time, driver_stop_times.describe()))\n",
    "\n",
    "            # collect set of stops for the given route\n",
    "            route_stops = route_stop_df[route_stop_df['route_id'] == route_id]\n",
    "            route_stops = route_stops.sort_values(['heading', 'sequence'])\n",
    "            route_stops.set_index(pd.RangeIndex(route_stops.shape[0]),\n",
    "                                  inplace=True)\n",
    "            # print('route {} stops:\\n{}'.format(route_id, route_stops.describe()))\n",
    "\n",
    "            route_trip_list = construct_trip_list(route_stops, driver_stop_times)\n",
    "            # print('found {} route trips'.format(len(route_trip_list)))\n",
    "\n",
    "            # assume that warning and stop_time records have seconds in their\n",
    "            # timestamp\n",
    "            for j in range(len(route_trip_list)):\n",
    "              trip = route_trip_list[j]\n",
    "              trip.driver_id = driver_id\n",
    "              trip.bus_number = driver_assignments.iloc[i].bus_number\n",
    "              # print('trip_start_time: {}, trip_end_time: {}'.format(trip_start_time, trip_end_time))\n",
    "\n",
    "              trip_warnings = warning_df.query(\n",
    "                'bus_number == @trip.bus_number & '\n",
    "                'loc_time >= @trip.start_time & '\n",
    "                'loc_time < @trip.end_time')\n",
    "\n",
    "              if trip_warnings.shape[0] == 0:\n",
    "                # print('Trip {} for run {}: {} has no warnings'.format(\n",
    "                #   j, i, [vehicle_id, driver_id, route_id, trip.start_time,\n",
    "                #       trip.end_time, trip.heading, trip.stop_count]))\n",
    "\n",
    "                trips_with_no_warnings += 1\n",
    "              # else:\n",
    "              #   print('Trip {} for {} has warnings'.format(\n",
    "              #     i, [vehicle_id, driver_id, route_id, trip.start_time, trip.end_time, trip.heading]))\n",
    "\n",
    "              warning_assignments = trip_warnings[\n",
    "                ['vehicle_id', 'driver_id', 'route_id']]\n",
    "\n",
    "              # print('pre-assignment: {}'.format(warning_df.loc[trip_warnings.index]))\n",
    "              # warning_df['vehicle_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   vehicle_id, trip_warnings.shape[0])\n",
    "              # warning_df['driver_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   driver_id, trip_warnings.shape[0])\n",
    "              # warning_df['route_id'].loc[trip_warnings.index] = np.tile(\n",
    "              #   route_id, trip_warnings.shape[0])\n",
    "              # print('post-assignment: {}'.format(warning_df.loc[trip_warnings.index]))\n",
    "\n",
    "              # print('pre-assignment: {}'.format(trip_warnings.head(1)))\n",
    "              trip_warnings.loc[:, 'vehicle_id'] = np.tile(\n",
    "                vehicle_id, trip_warnings.shape[0])\n",
    "              trip_warnings.loc[:, 'driver_id'] = np.tile(\n",
    "                driver_id, trip_warnings.shape[0])\n",
    "              trip_warnings.loc[:, 'route_id'] = np.tile(\n",
    "                route_id, trip_warnings.shape[0])\n",
    "              # print('post-assignment: {}'.format(trip_warnings.head(1)))\n",
    "\n",
    "              # if not np.all(warning_assignments.values == 0):\n",
    "              #   print('Assigning some warnings to trip\\n{}: {}\\nthat have '\n",
    "              #         'already been assigned to\\n{}'.format(i, [\n",
    "              #     vehicle_id, driver_id, route_id, trip.start_time,\n",
    "              #     trip.end_time, trip.heading], warning_assignments))\n",
    "\n",
    "              trip.warnings = trip_warnings\n",
    "              # what if we use only arrive_at to define both the start and end\n",
    "              # of a trip, and then split warnings using > and <= at trip joints\n",
    "\n",
    "              # print('trip warnings: {}'.format(trip.warnings))\n",
    "\n",
    "            global_trip_list.extend(route_trip_list)\n",
    "    else:\n",
    "      print('missing definition for route with id {}'.format(route_id))\n",
    "\n",
    "  print('valid_trip_count: {}'.format(valid_trip_count))\n",
    "  print('invalid_trip_count: {}'.format(invalid_trip_count))\n",
    "  print('pseudo_invalid_trip_count: {}'.format(pseudo_invalid_trip_count))\n",
    "  print('trips_with_no_warnings: {}'.format(trips_with_no_warnings))\n",
    "  # TODO: handle unassigned warnings\n",
    "  return global_trip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_longitudinal_data_product(trip_list):\n",
    "  \"\"\"Given a list of Trip objects with warnings assigned, create longitudinal\n",
    "  records and return them as a numpy array \"\"\"\n",
    "  output_data = np.ndarray((len(trip_list),), dtype=longitudinal_type)\n",
    "\n",
    "  # trip being aggregated\n",
    "  for i in range(len(trip_list)):\n",
    "    trip = trip_list[i]\n",
    "\n",
    "    trip_data = np.array([[\n",
    "      trip.route_name, trip.route_id, trip.heading, trip.driver_id, trip.vehicle_id,\n",
    "      trip.bus_number, trip.start_time, trip.end_time]])\n",
    "\n",
    "    unique_warnings, counts = np.unique(\n",
    "      trip.warnings.loc[:, 'warning_name'].values, return_counts=True)\n",
    "\n",
    "    warning_data = np.zeros((1, warnings_header.shape[0]))\n",
    "\n",
    "    for j in range(unique_warnings.shape[0]):\n",
    "      index = np.nonzero(warnings_header == unique_warnings[j])\n",
    "\n",
    "      if len(index) > 0:\n",
    "        assert len(index) == 1\n",
    "        warning_data[0, index] = counts[j]\n",
    "\n",
    "    trip_data = np.squeeze(np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "    output_data[i] = tuple(trip_data)\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data\n",
    "\n",
    "\n",
    "def construct_hotspot_data_product(trip_list):\n",
    "  output_data = np.ndarray(\n",
    "    (sum([trip.warnings.shape[0] for trip in trip_list]),), dtype=hotspot_type)\n",
    "\n",
    "  index = 0\n",
    "\n",
    "  for trip in trip_list:\n",
    "    if trip.warnings.shape[0] > 0:\n",
    "      warning_data = trip.warnings.loc[:, ['loc_time', 'warning_name',\n",
    "                                          'latitude', 'longitude']].values\n",
    "\n",
    "      trip_data = np.tile([\n",
    "        trip.route_name, trip.route_id, trip.heading, trip.driver_id,\n",
    "        trip.vehicle_id, trip.bus_number], (warning_data.shape[0], 1))\n",
    "\n",
    "      output_data[index:index + warning_data.shape[0]] = np.apply_along_axis(\n",
    "        to_tuple, 1, np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "      index += warning_data.shape[0]\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also identify duplicates when a record is dropped for the second time\n",
    "def identify_unassigned_warnings(trip_list, warning_df):\n",
    "  \"\"\"use the indices of warning data frames assigned to trips to identify\n",
    "  warnings in warning_df that are not assigned to any trip, \"\"\"\n",
    "  w = warning_df.copy()\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for trip in trip_list:\n",
    "    try:\n",
    "      w = w.drop(trip.warnings.index)\n",
    "    except ValueError as ve:\n",
    "      print('1. {}'.format(ve))\n",
    "      try:\n",
    "        w = w.drop(list(set(\n",
    "          warning_df.index.values).intersection(trip.warnings.index.values)))\n",
    "      except Exception as e:\n",
    "        print('2. {}'.format(e))\n",
    "      # pass\n",
    "\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for i in range(0, w.shape[0], 10000):\n",
    "    print(w.iloc[i])\n",
    "\n",
    "  print('final w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converted from .py to arguments above\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument('--db_path', default='ituran_synchromatics_data.sqlite')\n",
    "  parser.add_argument('--route_stop_table_name', default='route_stop')\n",
    "  parser.add_argument('--stop_event_table_name', default='stop_time')\n",
    "  parser.add_argument('--driver_schedule_table_name',\n",
    "                      default='vehicle_assignment')\n",
    "  parser.add_argument('--warning_table_name', default='warning')\n",
    "  parser.add_argument('--hotspot_record_table_name',\n",
    "                      default='hotspot_data_product')\n",
    "  parser.add_argument('--longitudinal_record_table_name',\n",
    "                      default='longitudinal_data_product')\n",
    "  parser.add_argument('--if_exists', default='append')\n",
    "\n",
    "  args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start batching over months\n",
    "\n",
    "The next several steps work across entire time frame, but at warning_ext and trip_list, fails. Try to split these next by month and stitch together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = ['01/01/2018 00:00:00', '02/01/2018 00:00:00', '03/01/2018 00:00:00', '04/01/2018 00:00:00', '05/01/2018 00:00:00', '06/01/2018 00:00:00', \n",
    "          '07/01/2018 00:00:00', '08/01/2018 00:00:00', '09/01/2018 00:00:00', '10/01/2018 00:00:00', '11/01/2018 00:00:00', '12/01/2018 00:00:00']\n",
    "stops = ['01/31/2018 23:59:59', '02/28/2018 23:59:59', '03/31/2018 23:59:59', '04/30/2018 23:59:59', '05/31/2018 23:59:59', '06/30/2018 23:59:59', \n",
    "         '07/31/2018 23:59:59', '08/31/2018 23:59:59', '09/30/2018 23:59:59', '10/31/2018 23:59:59', '11/30/2018 23:59:59', '12/31/2018 23:59:59']\n",
    "\n",
    "monthbatch = pd.DataFrame.from_records({'starts': starts, 'stops': stops})\n",
    "\n",
    "monthbatch = monthbatch.iloc[3:4,] # just select April as a test\n",
    "# monthbatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starts</th>\n",
       "      <th>stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2018 00:00:00</td>\n",
       "      <td>04/30/2018 23:59:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                starts                stops\n",
       "3  04/01/2018 00:00:00  04/30/2018 23:59:59"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_time_df:\n",
      "            stop_id       route_id     vehicle_id  arrival_latitude  \\\n",
      "count  5.609770e+05  560977.000000  560977.000000     560977.000000   \n",
      "mean   1.052869e+05    1949.623131    1574.087727         34.046057   \n",
      "std    1.566695e+05    3247.782537    1190.799531          0.046499   \n",
      "min    4.219900e+04     296.000000     324.000000          0.000000   \n",
      "25%    9.046400e+04     297.000000     363.000000         34.040878   \n",
      "50%    9.095900e+04     298.000000    1603.000000         34.048454   \n",
      "75%    9.142400e+04     408.000000    1642.000000         34.052856   \n",
      "max    2.294803e+06    8435.000000    3809.000000         34.067383   \n",
      "\n",
      "       arrival_longitude  departure_latitude  departure_longitude  \\\n",
      "count      560977.000000       560977.000000        560977.000000   \n",
      "mean         -118.253245           34.046081          -118.253257   \n",
      "std             0.158301            0.046502             0.158303   \n",
      "min          -118.291748            0.000000          -118.291931   \n",
      "25%          -118.259277           34.040997          -118.259087   \n",
      "50%          -118.254173           34.048454          -118.254410   \n",
      "75%          -118.245140           34.052952          -118.245071   \n",
      "max             0.000000           34.067383             0.000000   \n",
      "\n",
      "       stop_time_id  \n",
      "count  5.609770e+05  \n",
      "mean   1.437827e+07  \n",
      "std    8.372094e+06  \n",
      "min    2.690390e+05  \n",
      "25%    9.785843e+06  \n",
      "50%    1.786681e+07  \n",
      "75%    2.289360e+07  \n",
      "max    2.324761e+07  \n",
      "vehicle_assignment_df:\n",
      "            stop_id       route_id     vehicle_id  arrival_latitude  \\\n",
      "count  5.609770e+05  560977.000000  560977.000000     560977.000000   \n",
      "mean   1.052869e+05    1949.623131    1574.087727         34.046057   \n",
      "std    1.566695e+05    3247.782537    1190.799531          0.046499   \n",
      "min    4.219900e+04     296.000000     324.000000          0.000000   \n",
      "25%    9.046400e+04     297.000000     363.000000         34.040878   \n",
      "50%    9.095900e+04     298.000000    1603.000000         34.048454   \n",
      "75%    9.142400e+04     408.000000    1642.000000         34.052856   \n",
      "max    2.294803e+06    8435.000000    3809.000000         34.067383   \n",
      "\n",
      "       arrival_longitude  departure_latitude  departure_longitude  \\\n",
      "count      560977.000000       560977.000000        560977.000000   \n",
      "mean         -118.253245           34.046081          -118.253257   \n",
      "std             0.158301            0.046502             0.158303   \n",
      "min          -118.291748            0.000000          -118.291931   \n",
      "25%          -118.259277           34.040997          -118.259087   \n",
      "50%          -118.254173           34.048454          -118.254410   \n",
      "75%          -118.245140           34.052952          -118.245071   \n",
      "max             0.000000           34.067383             0.000000   \n",
      "\n",
      "       stop_time_id  \n",
      "count  5.609770e+05  \n",
      "mean   1.437827e+07  \n",
      "std    8.372094e+06  \n",
      "min    2.690390e+05  \n",
      "25%    9.785843e+06  \n",
      "50%    1.786681e+07  \n",
      "75%    2.289360e+07  \n",
      "max    2.324761e+07  \n",
      "warning_df:\n",
      "            stop_id       route_id     vehicle_id  arrival_latitude  \\\n",
      "count  5.609770e+05  560977.000000  560977.000000     560977.000000   \n",
      "mean   1.052869e+05    1949.623131    1574.087727         34.046057   \n",
      "std    1.566695e+05    3247.782537    1190.799531          0.046499   \n",
      "min    4.219900e+04     296.000000     324.000000          0.000000   \n",
      "25%    9.046400e+04     297.000000     363.000000         34.040878   \n",
      "50%    9.095900e+04     298.000000    1603.000000         34.048454   \n",
      "75%    9.142400e+04     408.000000    1642.000000         34.052856   \n",
      "max    2.294803e+06    8435.000000    3809.000000         34.067383   \n",
      "\n",
      "       arrival_longitude  departure_latitude  departure_longitude  \\\n",
      "count      560977.000000       560977.000000        560977.000000   \n",
      "mean         -118.253245           34.046081          -118.253257   \n",
      "std             0.158301            0.046502             0.158303   \n",
      "min          -118.291748            0.000000          -118.291931   \n",
      "25%          -118.259277           34.040997          -118.259087   \n",
      "50%          -118.254173           34.048454          -118.254410   \n",
      "75%          -118.245140           34.052952          -118.245071   \n",
      "max             0.000000           34.067383             0.000000   \n",
      "\n",
      "       stop_time_id  \n",
      "count  5.609770e+05  \n",
      "mean   1.437827e+07  \n",
      "std    8.372094e+06  \n",
      "min    2.690390e+05  \n",
      "25%    9.785843e+06  \n",
      "50%    1.786681e+07  \n",
      "75%    2.289360e+07  \n",
      "max    2.324761e+07  \n",
      "warning_df head:\n",
      "   stop_id  route_id  vehicle_id                  arrived_at  \\\n",
      "0   894678       296         324  2018-04-04 06:09:51.000000   \n",
      "1   894678       296         324  2018-04-04 06:09:51.000000   \n",
      "\n",
      "   arrival_latitude  arrival_longitude                 departed_at  \\\n",
      "0         34.048077        -118.257935  2018-04-04 06:10:03.000000   \n",
      "1         34.048077        -118.257935  2018-04-04 06:10:03.000000   \n",
      "\n",
      "   departure_latitude  departure_longitude  stop_time_id  vehicle_id  \\\n",
      "0           34.048035          -118.257797      11956202           0   \n",
      "1           34.048035          -118.257797      11956395           0   \n",
      "\n",
      "   driver_id  route_id  \n",
      "0          0         0  \n",
      "1          0         0  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over months\n",
    "for index, row in monthbatch.iterrows():\n",
    "    \n",
    "    db_path = 'sqlite:///' + path.join(project_root_dir, 'ituran_synchromatics_data.sqlite')\n",
    "\n",
    "    db = create_engine(db_path)\n",
    "\n",
    "    route_stop_df = pd.read_sql_table(route_stop_table_name, db)\n",
    "    # print('route_stop_df:\\n{}'.format(route_stop_df.describe()))\n",
    "\n",
    "    # Allow for a subset of data to be processed based on a date range\n",
    "    # start_datetime_str = '02/01/2018 00:00:00'\n",
    "    # start_datetime = datetime.strptime(\n",
    "    #   start_datetime_str, '%m/%d/%Y %H:%M:%S').strftime('%m-%d-%Y %H:%M:%S')\n",
    "    start_datetime = datetime.strptime(row['starts'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # end_datetime_str = '02/28/2018 23:59:59'\n",
    "    # end_datetime = datetime.strptime(\n",
    "    #   end_datetime_str, '%m/%d/%Y %H:%M:%S').strftime('%m-%d-%Y %H:%M:%S')\n",
    "    end_datetime = datetime.strptime(row['stops'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        stop_time_df = pd.read_sql(\n",
    "            'select * from {} where arrived_at >= datetime(\\'{}\\') and arrived_at <= '\n",
    "            'datetime(\\'{}\\')'.format(stop_event_table_name, start_datetime,\n",
    "                                      end_datetime), con=db)\n",
    "    else:\n",
    "        stop_time_df = pd.read_sql_table(stop_event_table_name, db)\n",
    "\n",
    "    print('stop_time_df:\\n{}'.format(stop_time_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        vehicle_assignment_df = pd.read_sql(\n",
    "            'select * from {} where arrived_at >= datetime(\\'{}\\') and arrived_at <= datetime(\\'{}\\')'.format(stop_event_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        vehicle_assignment_df = pd.read_sql_table(driver_schedule_table_name, db)\n",
    "\n",
    "    print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        warning_df = pd.read_sql(\n",
    "            'select * from {} where arrived_at >= \\'{}\\' and arrived_at <= \\'{}\\''.format(stop_event_table_name, start_datetime,\n",
    "                            end_datetime), con=db)\n",
    "    else:\n",
    "        warning_df = pd.read_sql_table(warning_table_name, db)\n",
    "    print('warning_df:\\n{}'.format(warning_df.describe()))\n",
    "    \n",
    "        # extend warning df to include columns that uniquely identify trips so that\n",
    "    # warnings assigned to multiple runs can be discovered.\n",
    "    warning_ext = pd.DataFrame(\n",
    "        data=np.zeros((warning_df.shape[0], 3), dtype=np.uint32),\n",
    "        columns=['vehicle_id', 'driver_id', 'route_id'], index=warning_df.index)\n",
    "\n",
    "    warning_df = pd.concat([warning_df, warning_ext], axis=1)\n",
    "\n",
    "    print('warning_df head:\\n{}'.format(warning_df.head(2)))\n",
    "    \n",
    "    trip_list = assign_warnings_to_trips(\n",
    "        route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\n",
    "    \n",
    "    print('found {} total trips'.format(len(trip_list)))\n",
    "\n",
    "    # unassigned_warning_data = identify_unassigned_warnings(trip_list, warning_df)\n",
    "    # unassigned_warning_data.to_sql(\n",
    "    #   'unassigned_warning', db, if_exists=args.if_exists, chunksize=1000000,\n",
    "    #   index=False)\n",
    "    # print(unassigned_warning_data.describe())\n",
    "\n",
    "    longitudinal_data = construct_longitudinal_data_product(trip_list)\n",
    "      longitudinal_data.to_sql(\n",
    "        longitudinal_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "\n",
    "    print(longitudinal_data.describe())\n",
    "\n",
    "    hotspot_data = construct_hotspot_data_product(trip_list)\n",
    "      hotspot_data.to_sql(\n",
    "        hotspot_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "    print(hotspot_data.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
