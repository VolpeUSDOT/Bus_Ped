{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate products\n",
    "\n",
    "Follows Step 4, `04_add_stop_times_to_db.ipynb`\n",
    "\n",
    "**In process for `ituran_synchromatics_data.sqlite` in Data Integration - All Months**\n",
    "\n",
    "This script creates or replaces a table in the database at the supplied\n",
    "path that contains the set of stops for each of five Downtown DASH routes\n",
    "\n",
    "This script creates or replaces two tables in the database at the supplied\n",
    "path that contain 'clean' subsets of LADOT DASH trip data, where a clean trip is\n",
    "defined as having a pair of 'terminal' stops with a sequence of all northbound\n",
    "stops followed by all southbound stops (or vice versa) in between, and having\n",
    "a number of stop events no greater than the total number of stops that\n",
    "constitute a round trip on the route. A terminal stop is a stop where drivers\n",
    "transition their shifts.\n",
    "\n",
    "TODO: resolve issues that prevent all stop events from being included in the\n",
    "data product, e.g. when buses return to a depo from a stop other than the\n",
    "terminal, or when a driver running multiple contiguous rounds trips in a\n",
    "single shift does not stop at the terminal between two bounds.\n",
    "\n",
    "The hotspot_data_product table contains per-warning records for the purpose of\n",
    "hotspot analysis and the longitudinal_data_product table contains per-trip\n",
    "records, with warnings aggegated into counts for the purpose of longitudinal\n",
    "analysis.\n",
    "\n",
    "Data product construction is performed in three phases. First, individual trips\n",
    "are identified in construct_trip_list(), then corresponding warnings are\n",
    "assigned to each trip based on a time range and a vehicle id in\n",
    "assign_warnings_to_trips(), and finally either a hotspot or a longitudinal data\n",
    "product is constructed given the trips and their warnings in\n",
    "construct_hotspot_data_product() or construct_longitudinal_data_product()\n",
    "\n",
    "TODO: log print statements\n",
    "TODO: only db read stop events in the date range across driver schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunk by month and multiprocess**\n",
    "\n",
    "In process. Idea now (2019-04-01) is to split the job into tasks by month, then use `multiprocessing` to process multiple month at a time. \n",
    "\n",
    "Start with batching by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress warnings\n",
    "from multiprocessing import Process, Queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted from parser, adding project root dir\n",
    "project_root_dir = r'\\\\vntscex.local\\DFS\\3BC-Share$_Mobileye_Data\\Data\\Data Integration - All Months' \n",
    "\n",
    "db_path='ituran_synchromatics_data.sqlite'\n",
    "route_stop_table_name='route_stop'\n",
    "stop_event_table_name='stop_time'\n",
    "driver_schedule_table_name='vehicle_assignment'\n",
    "warning_table_name='warning'\n",
    "hotspot_record_table_name='hotspot_data_product'\n",
    "longitudinal_record_table_name='longitudinal_data_product'\n",
    "if_exists='append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define hostpot table column names and a custom data type fo organizing data\n",
    "# into records\n",
    "hotspot_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'loc_time', 'warning_name', 'latitude', 'longitude'])\n",
    "\n",
    "hotspot_type = np.dtype([\n",
    "  (hotspot_header[0], np.unicode_, 6), (hotspot_header[1], np.uint32),\n",
    "  (hotspot_header[2], np.unicode_, 10), (hotspot_header[3], np.uint32),\n",
    "  (hotspot_header[4], np.uint32), (hotspot_header[5], np.uint32),\n",
    "  (hotspot_header[6], datetime), (hotspot_header[7], np.unicode_, 34),\n",
    "  (hotspot_header[8], np.float64), (hotspot_header[9], np.float64)])\n",
    "\n",
    "# define longitudinal table column names and a custom data type fo organizing\n",
    "# data into records\n",
    "longitudinal_header = np.array([\n",
    "  'route_name', 'route_id', 'heading', 'driver_id', 'vehicle_id', 'bus_number',\n",
    "  'start_time', 'end_time', 'ME - Pedestrian Collision Warning',\n",
    "  'ME - Pedestrian In Range Warning', 'PCW-LF', 'PCW-LR', 'PCW-RR',\n",
    "  'PDZ - Left Front', 'PDZ-LR', 'PDZ-R', 'Safety - Braking - Aggressive',\n",
    "  'Safety - Braking - Dangerous'])\n",
    "\n",
    "longitudinal_type = np.dtype([\n",
    "  (longitudinal_header[0], np.unicode_, 6), (longitudinal_header[1], np.uint32),\n",
    "  (longitudinal_header[2], np.unicode_, 10), (longitudinal_header[3], np.uint32),\n",
    "  (longitudinal_header[4], np.uint32), (longitudinal_header[5], np.uint32),\n",
    "  (longitudinal_header[6], datetime),\n",
    "  (longitudinal_header[7], datetime), (longitudinal_header[8], np.uint16),\n",
    "  (longitudinal_header[9], np.uint16), (longitudinal_header[10], np.uint16),\n",
    "  (longitudinal_header[11], np.uint16), (longitudinal_header[12], np.uint16),\n",
    "  (longitudinal_header[13], np.uint16), (longitudinal_header[14], np.uint16),\n",
    "  (longitudinal_header[15], np.uint16), (longitudinal_header[16], np.uint16),\n",
    "  (longitudinal_header[17], np.uint16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a separate collection of warning headers will be used to first create warning\n",
    "# count data before concatenating them with trip data to form longitudinal\n",
    "# records\n",
    "warnings_header = longitudinal_header[8:]\n",
    "\n",
    "valid_trip_count = 0\n",
    "invalid_trip_count = 0\n",
    "pseudo_invalid_trip_count = 0\n",
    "trips_with_no_warnings = 0\n",
    "\n",
    "# a Run object is used to organize an individual trip's properties together with\n",
    "# a collection of warnings that may vary in length from trip to trip\n",
    "class Trip:\n",
    "  def __init__(self, route_name, route_id, heading, vehicle_id, start_time,\n",
    "               end_time, stop_count, driver_id=None, bus_number=None, warnings=None):\n",
    "    self.route_name = route_name\n",
    "    self.route_id = route_id\n",
    "    self.heading = heading\n",
    "    self.vehicle_id = vehicle_id\n",
    "    self.start_time = start_time\n",
    "    self.end_time = end_time\n",
    "    self.driver_id = driver_id\n",
    "    self.bus_number = bus_number\n",
    "    self.warnings = warnings\n",
    "    self.stop_count = stop_count\n",
    "\n",
    "\n",
    "# numpy arrays of custom dtype expect elements to be tuples. Because\n",
    "# longitudinal records are created in batches, organization of data into a tuple\n",
    "# must be applied row-wise across the batch dimension\n",
    "def to_tuple(element):\n",
    "    return np.array(tuple(element), dtype=hotspot_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(process_queue, stop_times=None, terminal_stop_indices=None,\n",
    "         route_stops=None, northbound_stop_ids=None, southbound_stop_ids=None):\n",
    "  def is_northbound_fn(stop_id):\n",
    "    # print('n_stop_id: {}'.format(stop_id))\n",
    "    return True if stop_id in northbound_stop_ids else False\n",
    "\n",
    "  def is_southbound_fn(stop_id):\n",
    "    # print('s_stop_id: {}'.format(southbound_stop_ids))\n",
    "    return True if stop_id in southbound_stop_ids else False\n",
    "\n",
    "  i = process_queue.get()\n",
    "  # treat any stops preceding the first terminal as a partial trip\n",
    "  if i == -1:\n",
    "    try:\n",
    "      round_trip_stop_times = \\\n",
    "        stop_times.loc[stop_times.index.values[0]:terminal_stop_indices[0]]\n",
    "      # print('{} stop times found before first terminal'.format(\n",
    "      #   round_trip_stop_times.shape[0]))\n",
    "    except:\n",
    "      # continue\n",
    "      return []\n",
    "  # since the last trip may not end at the terminal, grab all stops after\n",
    "  # the last terminal. If the last trip truly did end at the terminal, the\n",
    "  # below code should branch out appropriately\n",
    "  elif i == len(terminal_stop_indices) - 1:\n",
    "    try:\n",
    "      round_trip_stop_times = \\\n",
    "        stop_times.loc[terminal_stop_indices[i]:stop_times.index.values[-1]]\n",
    "      # print('{} stop times found after last terminal'.format(\n",
    "      #   round_trip_stop_times.shape[0]))\n",
    "    except:\n",
    "      # continue\n",
    "      return []\n",
    "  else:\n",
    "    round_trip_stop_times = \\\n",
    "      stop_times.loc[terminal_stop_indices[i]:terminal_stop_indices[i+1]]\n",
    "    # print('round_trip_stop_times_range: ({}, {})'.format(\n",
    "    #   terminal_stop_indices[i], terminal_stop_indices[i+1]))\n",
    "\n",
    "  local_trip_list = []\n",
    "  # ignore ranges that are less than 3 stops long as these are probably\n",
    "  # sequences of multiple records representing a single event\n",
    "  if 2 <= round_trip_stop_times.shape[0]:  # <= route_stops.shape[0] * 1:#\n",
    "    #confirm that the sequence of trips divides cleanly across the two bounds\n",
    "    are_northbound = round_trip_stop_times['stop_id'].apply(is_northbound_fn)\n",
    "    # print('are_northbound: {}'.format(are_northbound.values))\n",
    "\n",
    "    are_southbound = round_trip_stop_times['stop_id'].apply(is_southbound_fn)\n",
    "    # print('are_southbound: {}'.format(are_southbound.values))\n",
    "\n",
    "    are_equal = are_northbound == are_southbound\n",
    "    # print('are_equal: {}'.format(are_equal.values))\n",
    "\n",
    "    if not are_equal.any():\n",
    "      # ignore the 0th stop since the southbound terminal may precede an entire\n",
    "      # northbound trip or vice versa, making a bound appear not uniform\n",
    "      northbound_indices = are_northbound.iloc[1:-1][\n",
    "        are_northbound.iloc[1:-1] == True].index\n",
    "      # print('northbound_indices:\\n{}'.format(northbound_indices))\n",
    "      southbound_indices = are_southbound.iloc[1:-1][\n",
    "        are_southbound.iloc[1:-1] == True].index\n",
    "      # print('southbound_indices:\\n{}'.format(southbound_indices))\n",
    "      # assume argwhere will preserve the index ordering\n",
    "      if northbound_indices.shape[0] > 2 and southbound_indices.shape[0] > 2:\n",
    "        route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "        route_name = route_stops.iloc[0]['route_name']\n",
    "        vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "        # valid_trip_count += 2\n",
    "        # in this round trip, the northbound trip precedes the southbound trip\n",
    "        # if northbound_indices[-1] < southbound_indices[0]:\n",
    "        if np.all(northbound_indices < southbound_indices[0]) \\\n",
    "            and np.all(northbound_indices[-1] < southbound_indices):\n",
    "          # the southbound trip\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.loc[\n",
    "            northbound_indices[-1]]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "          local_trip_list.append(Trip(\n",
    "            route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "            northbound_indices.shape[0]))\n",
    "\n",
    "          start_time = round_trip_stop_times.loc[\n",
    "            northbound_indices[-1]]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          local_trip_list.append(Trip(\n",
    "            route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "            southbound_indices.shape[0]))\n",
    "        # elif northbound_indices[0] > southbound_indices[-1]:\n",
    "        elif np.all(northbound_indices[0] > southbound_indices) \\\n",
    "            and np.all(northbound_indices > southbound_indices[-1]):\n",
    "          start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.loc[\n",
    "            southbound_indices[-1]]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          local_trip_list.append(Trip(\n",
    "            route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "            southbound_indices.shape[0]))\n",
    "\n",
    "          start_time = round_trip_stop_times.loc[\n",
    "            southbound_indices[-1]]['departed_at']\n",
    "          # print('start_time: {}'.format(start_time))\n",
    "          end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "          # print('end_time: {}'.format(end_time))\n",
    "\n",
    "          local_trip_list.append(Trip(\n",
    "            route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "            northbound_indices.shape[0]))\n",
    "      elif southbound_indices.shape[0] >= 2 \\\n",
    "          and northbound_indices.shape[0] == 0:\n",
    "        # valid_trip_count += 1\n",
    "        route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "        route_name = route_stops.iloc[0]['route_name']\n",
    "        vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "        start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "        # print('start_time: {}'.format(start_time))\n",
    "        end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "        # print('end_time: {}'.format(end_time))\n",
    "\n",
    "        local_trip_list.append(Trip(\n",
    "          route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "          southbound_indices.shape[0]))\n",
    "      elif southbound_indices.shape[0] == 0 \\\n",
    "          and northbound_indices.shape[0] >= 2:\n",
    "        # valid_trip_count += 1\n",
    "        route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "        route_name = route_stops.iloc[0]['route_name']\n",
    "        vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "        start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "        # print('start_time: {}'.format(start_time))\n",
    "        end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "        # print('end_time: {}'.format(end_time))\n",
    "\n",
    "        local_trip_list.append(Trip(\n",
    "          route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "          northbound_indices.shape[0]))\n",
    "      # else:\n",
    "      #   pseudo_invalid_trip_count += 1\n",
    "  print('Process {} will return {} trips.'.format(i, len(local_trip_list)))\n",
    "  process_queue.put(local_trip_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trip_list(route_stops, stop_times):\n",
    "  \"\"\"\n",
    "  Given a time-ordered sequence of stops a bus traveled to or past, and the\n",
    "  arrival time for each stop, extract instances of round trips (between the\n",
    "  departure from a terminal to the arrival at that same stop. Records for which\n",
    "  consecutive terminal stops have an unreasonable number of intermediate stops\n",
    "  (e.g. more than the total number of stops that constitute a route) will be\n",
    "  ignored.\n",
    "  \"\"\"\n",
    "  # global valid_trip_count\n",
    "  # global invalid_trip_count\n",
    "  # global pseudo_invalid_trip_count\n",
    "  # global trips_with_no_warnings\n",
    "\n",
    "  global_trip_list = []\n",
    "  # print('stop_times: {}'.format(stop_times))\n",
    "\n",
    "  terminal_stop_id = route_stops[\n",
    "    route_stops['is_terminal'] == True]['stop_id'].squeeze()\n",
    "  # print('terminal_stop_id: {}'.format(terminal_stop_id))\n",
    "\n",
    "  # assume that the stop_times have been sorted by arrived_at then departed_at\n",
    "  terminal_stop_indices = stop_times[\n",
    "    stop_times['stop_id'] == terminal_stop_id].index.values\n",
    "  # print('terminal_stop_indices: {}'.format(terminal_stop_indices))\n",
    "\n",
    "  northbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'N']['stop_id'].values\n",
    "  northbound_stop_ids = northbound_stop_ids.astype(np.uint32)\n",
    "  # print('northbound_stop_ids: {}'.format(northbound_stop_ids))\n",
    "\n",
    "  southbound_stop_ids = route_stops[\n",
    "    route_stops.heading == 'S']['stop_id'].values\n",
    "  southbound_stop_ids = southbound_stop_ids.astype(np.uint32)\n",
    "  # print('southbound_stop_ids: {}'.format(southbound_stop_ids))\n",
    "\n",
    "  def is_northbound_fn(stop_id):\n",
    "    # print('n_stop_id: {}'.format(stop_id))\n",
    "    return True if stop_id in northbound_stop_ids else False\n",
    "\n",
    "  def is_southbound_fn(stop_id):\n",
    "    # print('s_stop_id: {}'.format(southbound_stop_ids))\n",
    "    return True if stop_id in southbound_stop_ids else False\n",
    "\n",
    "  if len(terminal_stop_indices) > 0:\n",
    "    for i in [-1] + list(range(len(terminal_stop_indices))):\n",
    "      # treat any stops preceding the first terminal as a partial trip\n",
    "      if i == -1:\n",
    "        try:\n",
    "          round_trip_stop_times = \\\n",
    "            stop_times.loc[stop_times.index.values[0]:terminal_stop_indices[0]]\n",
    "          # print('{} stop times found before first terminal'.format(\n",
    "          #   round_trip_stop_times.shape[0]))\n",
    "        except:\n",
    "          continue\n",
    "      # since the last trip may not end at the terminal, grab all stops after\n",
    "      # the last terminal. If the last trip truly did end at the terminal, the\n",
    "      # below code should branch out appropriately\n",
    "      elif i == len(terminal_stop_indices) - 1:\n",
    "        try:\n",
    "          round_trip_stop_times = \\\n",
    "            stop_times.loc[terminal_stop_indices[i]:stop_times.index.values[-1]]\n",
    "          # print('{} stop times found after last terminal'.format(\n",
    "          #   round_trip_stop_times.shape[0]))\n",
    "        except:\n",
    "          continue\n",
    "      else:\n",
    "        round_trip_stop_times = \\\n",
    "          stop_times.loc[terminal_stop_indices[i]:terminal_stop_indices[i + 1]]\n",
    "        # print('round_trip_stop_times_range: ({}, {})'.format(\n",
    "        #   terminal_stop_indices[i], terminal_stop_indices[i+1]))\n",
    "\n",
    "      local_trip_list = []\n",
    "      # ignore ranges that are less than 3 stops long as these are probably\n",
    "      # sequences of multiple records representing a single event\n",
    "      if 2 <= round_trip_stop_times.shape[0]:  # <= route_stops.shape[0] * 1:#\n",
    "        # confirm that the sequence of trips divides cleanly across the two bounds\n",
    "        are_northbound = round_trip_stop_times['stop_id'].apply(is_northbound_fn)\n",
    "        # print('are_northbound: {}'.format(are_northbound.values))\n",
    "\n",
    "        are_southbound = round_trip_stop_times['stop_id'].apply(is_southbound_fn)\n",
    "        # print('are_southbound: {}'.format(are_southbound.values))\n",
    "\n",
    "        are_equal = are_northbound == are_southbound\n",
    "        # print('are_equal: {}'.format(are_equal.values))\n",
    "\n",
    "        if not are_equal.any():\n",
    "          # ignore the 0th stop since the southbound terminal may precede an entire\n",
    "          # northbound trip or vice versa, making a bound appear not uniform\n",
    "          northbound_indices = are_northbound.iloc[1:-1][\n",
    "            are_northbound.iloc[1:-1] == True].index\n",
    "          # print('northbound_indices:\\n{}'.format(northbound_indices))\n",
    "          southbound_indices = are_southbound.iloc[1:-1][\n",
    "            are_southbound.iloc[1:-1] == True].index\n",
    "          # print('southbound_indices:\\n{}'.format(southbound_indices))\n",
    "          # assume argwhere will preserve the index ordering\n",
    "          if northbound_indices.shape[0] > 2 and southbound_indices.shape[0] > 2:\n",
    "            route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "            route_name = route_stops.iloc[0]['route_name']\n",
    "            vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "            # valid_trip_count += 2\n",
    "            # in this round trip, the northbound trip precedes the southbound trip\n",
    "            # if northbound_indices[-1] < southbound_indices[0]:\n",
    "            if np.all(northbound_indices < southbound_indices[0]) \\\n",
    "                and np.all(northbound_indices[-1] < southbound_indices):\n",
    "              # the southbound trip\n",
    "              start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "              # print('start_time: {}'.format(start_time))\n",
    "              end_time = round_trip_stop_times.loc[\n",
    "                northbound_indices[-1]]['arrived_at']\n",
    "              # print('end_time: {}'.format(end_time))\n",
    "              local_trip_list.append(Trip(\n",
    "                route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "                northbound_indices.shape[0]))\n",
    "\n",
    "              start_time = round_trip_stop_times.loc[\n",
    "                northbound_indices[-1]]['departed_at']\n",
    "              # print('start_time: {}'.format(start_time))\n",
    "              end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "              # print('end_time: {}'.format(end_time))\n",
    "\n",
    "              local_trip_list.append(Trip(\n",
    "                route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "                southbound_indices.shape[0]))\n",
    "            elif np.all(northbound_indices[0] > southbound_indices) \\\n",
    "                and np.all(northbound_indices > southbound_indices[-1]):\n",
    "              start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "              # print('start_time: {}'.format(start_time))\n",
    "              end_time = round_trip_stop_times.loc[\n",
    "                southbound_indices[-1]]['arrived_at']\n",
    "              # print('end_time: {}'.format(end_time))\n",
    "\n",
    "              local_trip_list.append(Trip(\n",
    "                route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "                southbound_indices.shape[0]))\n",
    "\n",
    "              start_time = round_trip_stop_times.loc[\n",
    "                southbound_indices[-1]]['departed_at']\n",
    "              # print('start_time: {}'.format(start_time))\n",
    "              end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "              # print('end_time: {}'.format(end_time))\n",
    "\n",
    "              local_trip_list.append(Trip(\n",
    "                route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "                northbound_indices.shape[0]))\n",
    "          elif southbound_indices.shape[0] >= 2 \\\n",
    "              and northbound_indices.shape[0] == 0:\n",
    "            # valid_trip_count += 1\n",
    "            route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "            route_name = route_stops.iloc[0]['route_name']\n",
    "            vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            local_trip_list.append(Trip(\n",
    "              route_name, route_id, 'S', vehicle_id, start_time, end_time,\n",
    "              southbound_indices.shape[0]))\n",
    "          elif southbound_indices.shape[0] == 0 \\\n",
    "              and northbound_indices.shape[0] >= 2:\n",
    "            # valid_trip_count += 1\n",
    "            route_id = round_trip_stop_times.iloc[0]['route_id']\n",
    "            route_name = route_stops.iloc[0]['route_name']\n",
    "            vehicle_id = round_trip_stop_times.iloc[0]['vehicle_id']\n",
    "\n",
    "            start_time = round_trip_stop_times.iloc[0]['departed_at']\n",
    "            # print('start_time: {}'.format(start_time))\n",
    "            end_time = round_trip_stop_times.iloc[-1]['arrived_at']\n",
    "            # print('end_time: {}'.format(end_time))\n",
    "\n",
    "            local_trip_list.append(Trip(\n",
    "              route_name, route_id, 'N', vehicle_id, start_time, end_time,\n",
    "              northbound_indices.shape[0]))\n",
    "            # else:\n",
    "            #   pseudo_invalid_trip_count += 1\n",
    "      global_trip_list.extend(local_trip_list)\n",
    "\n",
    "  return global_trip_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_driver_assignment(\n",
    "    assignment_queue, driver_start_time, driver_end_time, bus_number, route_id,\n",
    "    driver_id, vehicle_id, warnings):\n",
    "  i = assignment_queue.get()\n",
    "\n",
    "  # here we assume that any bus on the given route for the given\n",
    "  # driver during a given trip (of multiple trips) will not switch to\n",
    "  # a different route and then switch back.\n",
    "\n",
    "  # although it is possible for some stops to be included that follow\n",
    "  # the driver's trip start time but precede the route's initial stop,\n",
    "  # warnings during that interval will be ignored and only those\n",
    "  # occurring after the first stop departure will be included\n",
    "  driver_stop_times = stop_time_df.query(\n",
    "    'route_id == @route_id & '\n",
    "    'vehicle_id == @vehicle_id & '\n",
    "    'departed_at >= @driver_start_time & '\n",
    "    'arrived_at < @driver_end_time')\n",
    "\n",
    "  driver_stop_times = driver_stop_times.sort_values(\n",
    "    ['arrived_at', 'departed_at'])\n",
    "\n",
    "  driver_stop_times.set_index(\n",
    "    pd.RangeIndex(driver_stop_times.shape[0]), inplace=True)\n",
    "\n",
    "  # collect set of stops for the given route\n",
    "  route_stops = route_stop_df[route_stop_df['route_id'] == route_id]\n",
    "  route_stops = route_stops.sort_values(['heading', 'sequence'])\n",
    "  route_stops.set_index(pd.RangeIndex(route_stops.shape[0]), inplace=True)\n",
    "\n",
    "  route_trip_list = construct_trip_list(route_stops, driver_stop_times)\n",
    "  print('found {} route trips'.format(len(route_trip_list)))\n",
    "\n",
    "  # assume that warning and stop_time records have seconds in their\n",
    "  # timestamp\n",
    "  for j in range(len(route_trip_list)):\n",
    "    trip = route_trip_list[j]\n",
    "    trip.driver_id = driver_id\n",
    "    trip.bus_number = bus_number\n",
    "\n",
    "    trip_warnings = warnings.query(\n",
    "      'bus_number == @trip.bus_number & '\n",
    "      'loc_time >= @trip.start_time & '\n",
    "      'loc_time < @trip.end_time')\n",
    "\n",
    "    if trip_warnings.shape[0] == 0:\n",
    "      trip_warnings.assign(vehicle_id=np.tile(vehicle_id, trip_warnings.shape[0]))\n",
    "      trip_warnings.assign(driver_id=np.tile(driver_id, trip_warnings.shape[0]))\n",
    "      trip_warnings.assign(route_id=np.tile(route_id, trip_warnings.shape[0]))\n",
    "\n",
    "      trip.warnings = trip_warnings\n",
    "\n",
    "  print('Process {} will return {} trips.'.format(i, len(route_trip_list)))\n",
    "\n",
    "  assignment_queue.put(route_trip_list)\n",
    "  assignment_queue.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_warnings_to_trips(\n",
    "  route_stop_df, stop_time_df, vehicle_assignment_df, warning_df):\n",
    "  \"\"\"\n",
    "  Given four pandas data frames representing warning events, route stops,\n",
    "  stop events and driver schedules, construct a list of individual route trips,\n",
    "  assign warning events that occurred during each trip to that trip, then return\n",
    "  the complete list.\n",
    "  \"\"\"\n",
    "  # global trips_with_no_warnings\n",
    "\n",
    "  global_trip_list = []\n",
    "  # print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "  # stop_time_df.sort_values(['arrived_at', 'departed_at'], inplace=True)\n",
    "  # stop_time_df.set_index(pd.RangeIndex(stop_time_df.shape[0]), inplace=True)\n",
    "\n",
    "  relevant_route_ids = stop_time_df['route_id'].unique()\n",
    "  print('route ids among stop times: {}'.format(relevant_route_ids))\n",
    "  # since DASH A routes are not in teh DB yet...\n",
    "  available_route_ids = route_stop_df['route_id'].unique()\n",
    "  print('route ids among route stops: {}'.format(available_route_ids))\n",
    "\n",
    "  for route_id in relevant_route_ids:\n",
    "    if route_id in available_route_ids:\n",
    "      # collect all driver assignments for the given route for all time\n",
    "      vehicles_that_ran_route = vehicle_assignment_df[\n",
    "        vehicle_assignment_df['route_id'] == route_id]\n",
    "      # print('relevant_vehicle_assignments:\\n{}'.format(relevant_vehicle_assignments))\n",
    "\n",
    "      # identify unique set of vehicle ids for all time\n",
    "      unique_vehicle_ids = vehicles_that_ran_route['vehicle_id'].unique()\n",
    "      # print('unique_vehicle_ids:\\n{}  '.format(unique_vehicle_ids))\n",
    "\n",
    "      for vehicle_id in unique_vehicle_ids:\n",
    "        relevant_vehicle_assignments = vehicles_that_ran_route[\n",
    "          vehicles_that_ran_route['vehicle_id'] == vehicle_id]\n",
    "\n",
    "        relevant_driver_ids = relevant_vehicle_assignments['driver_id'].unique()\n",
    "\n",
    "        for driver_id in relevant_driver_ids:\n",
    "          driver_assignments = relevant_vehicle_assignments[\n",
    "            relevant_vehicle_assignments['driver_id'] == driver_id]\n",
    "\n",
    "          if driver_assignments.shape[0] > 0:\n",
    "            processes = []\n",
    "            process_queues = []\n",
    "\n",
    "            print('Processing {} driver_assignments'.format(\n",
    "              driver_assignments.shape[0] + 1))\n",
    "\n",
    "            for i in range(driver_assignments.shape[0]):\n",
    "              process_queue = Queue(maxsize=1)\n",
    "              process_queue.put(i)\n",
    "              process_queues.append(process_queue)\n",
    "\n",
    "              process = Process(target=process_driver_assignment, args=(\n",
    "                process_queue, driver_assignments.iloc[i].start_time,\n",
    "                driver_assignments.iloc[i].end_time,\n",
    "                driver_assignments.iloc[i].bus_number, route_id, driver_id,\n",
    "                vehicle_id, warning_df))\n",
    "              process.start()\n",
    "              processes.append(process)\n",
    "\n",
    "            for p in processes:\n",
    "              p.join()\n",
    "\n",
    "            local_trip_list_list = []\n",
    "\n",
    "            for q in process_queues:\n",
    "              local_trip_list_list.append(q.get())\n",
    "              q.close()\n",
    "\n",
    "            for l in local_trip_list_list:\n",
    "              global_trip_list.extend(l)\n",
    "\n",
    "    else:\n",
    "      print('missing definition for route with id {}'.format(route_id))\n",
    "\n",
    "  # print('valid_trip_count: {}'.format(valid_trip_count))\n",
    "  # print('invalid_trip_count: {}'.format(invalid_trip_count))\n",
    "  # print('pseudo_invalid_trip_count: {}'.format(pseudo_invalid_trip_count))\n",
    "  # print('trips_with_no_warnings: {}'.format(trips_with_no_warnings))\n",
    "  # TODO: handle unassigned warnings\n",
    "  return global_trip_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_longitudinal_data_product(trip_list):\n",
    "  \"\"\"Given a list of Trip objects with warnings assigned, create longitudinal\n",
    "  records and return them as a numpy array \"\"\"\n",
    "  output_data = np.ndarray((len(trip_list),), dtype=longitudinal_type)\n",
    "\n",
    "  # trip being aggregated\n",
    "  for i in range(len(trip_list)):\n",
    "    trip = trip_list[i]\n",
    "\n",
    "    trip_data = np.array([[\n",
    "      trip.route_name, trip.route_id, trip.heading, trip.driver_id, trip.vehicle_id,\n",
    "      trip.bus_number, trip.start_time, trip.end_time]])\n",
    "\n",
    "    unique_warnings, counts = np.unique(\n",
    "      trip.warnings.loc[:, 'warning_name'].values, return_counts=True)\n",
    "\n",
    "    warning_data = np.zeros((1, warnings_header.shape[0]))\n",
    "\n",
    "    for j in range(unique_warnings.shape[0]):\n",
    "      index = np.nonzero(warnings_header == unique_warnings[j])\n",
    "\n",
    "      if len(index) > 0:\n",
    "        assert len(index) == 1\n",
    "        warning_data[0, index] = counts[j]\n",
    "\n",
    "    trip_data = np.squeeze(np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "    output_data[i] = tuple(trip_data)\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data\n",
    "\n",
    "\n",
    "def construct_hotspot_data_product(trip_list):\n",
    "  output_data = np.ndarray(\n",
    "    (sum([trip.warnings.shape[0] for trip in trip_list]),), dtype=hotspot_type)\n",
    "\n",
    "  index = 0\n",
    "\n",
    "  for trip in trip_list:\n",
    "    if trip.warnings.shape[0] > 0:\n",
    "      warning_data = trip.warnings.loc[:, ['loc_time', 'warning_name',\n",
    "                                          'latitude', 'longitude']].values\n",
    "\n",
    "      trip_data = np.tile([\n",
    "        trip.route_name, trip.route_id, trip.heading, trip.driver_id,\n",
    "        trip.vehicle_id, trip.bus_number], (warning_data.shape[0], 1))\n",
    "\n",
    "      output_data[index:index + warning_data.shape[0]] = np.apply_along_axis(\n",
    "        to_tuple, 1, np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "      index += warning_data.shape[0]\n",
    "\n",
    "  output_data = pd.DataFrame(output_data)\n",
    "\n",
    "  # print('output_data: {}'.format(output_data.describe()))\n",
    "\n",
    "  return output_data\n",
    "\n",
    "\n",
    "#also identify duplicates when a record is dropped for the second time\n",
    "def identify_unassigned_warnings(trip_list, warning_df):\n",
    "  \"\"\"use the indices of warning data frames assigned to trips to identify\n",
    "  warnings in warning_df that are not assigned to any trip, \"\"\"\n",
    "  w = warning_df.copy()\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for trip in trip_list:\n",
    "    try:\n",
    "      w = w.drop(trip.warnings.index)\n",
    "    except ValueError as ve:\n",
    "      print('1. {}'.format(ve))\n",
    "      try:\n",
    "        w = w.drop(list(set(\n",
    "          warning_df.index.values).intersection(trip.warnings.index.values)))\n",
    "      except Exception as e:\n",
    "        print('2. {}'.format(e))\n",
    "      # pass\n",
    "\n",
    "  print('initial w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  for i in range(0, w.shape[0], 10000):\n",
    "    print(w.iloc[i])\n",
    "\n",
    "  print('final w len: {}'.format(w.shape[0]))\n",
    "\n",
    "  return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converted from .py to arguments above\n",
    "```\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument('--db_path', default='ituran_synchromatics_data.sqlite')\n",
    "  parser.add_argument('--route_stop_table_name', default='route_stop')\n",
    "  parser.add_argument('--stop_event_table_name', default='stop_time')\n",
    "  parser.add_argument('--driver_schedule_table_name',\n",
    "                      default='vehicle_assignment')\n",
    "  parser.add_argument('--warning_table_name', default='warning')\n",
    "  parser.add_argument('--hotspot_record_table_name',\n",
    "                      default='hotspot_data_product')\n",
    "  parser.add_argument('--longitudinal_record_table_name',\n",
    "                      default='longitudinal_data_product')\n",
    "  parser.add_argument('--if_exists', default='append')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start batching over months\n",
    "\n",
    "The next several steps work across entire time frame, but at warning_ext and trip_list, fails. Try to split these next by month and stitch together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starts</th>\n",
       "      <th>stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2018 00:00:00</td>\n",
       "      <td>02/28/2018 23:59:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                starts                stops\n",
       "1  02/01/2018 00:00:00  02/28/2018 23:59:59"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts = ['01/01/2018 00:00:00', '02/01/2018 00:00:00', '03/01/2018 00:00:00', '04/01/2018 00:00:00', '05/01/2018 00:00:00', '06/01/2018 00:00:00', \n",
    "          '07/01/2018 00:00:00', '08/01/2018 00:00:00', '09/01/2018 00:00:00', '10/01/2018 00:00:00', '11/01/2018 00:00:00', '12/01/2018 00:00:00']\n",
    "stops = ['01/31/2018 23:59:59', '02/28/2018 23:59:59', '03/31/2018 23:59:59', '04/30/2018 23:59:59', '05/31/2018 23:59:59', '06/30/2018 23:59:59', \n",
    "         '07/31/2018 23:59:59', '08/31/2018 23:59:59', '09/30/2018 23:59:59', '10/31/2018 23:59:59', '11/30/2018 23:59:59', '12/31/2018 23:59:59']\n",
    "\n",
    "monthbatch = pd.DataFrame.from_records({'starts': starts, 'stops': stops})\n",
    "\n",
    "monthbatch = monthbatch.iloc[1:2,] # just select Feb as a test\n",
    "# monthbatch = monthbatch.iloc[2:3,] # just select March as a test\n",
    "# monthbatch = monthbatch.iloc[5:6,] # just select June as a test\n",
    "\n",
    "monthbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "db_path = 'sqlite:///' + path.join(project_root_dir, 'ituran_synchromatics_data.sqlite')\n",
    "\n",
    "db = create_engine(db_path)\n",
    "\n",
    "route_stop_df = pd.read_sql_table(route_stop_table_name, db)\n",
    "# print('route_stop_df:\\n{}'.format(route_stop_df.describe()))\n",
    "\n",
    "# Allow for a subset of data to be processed based on a date range\n",
    "start_datetime = datetime.strptime(monthbatch.iloc[0,0], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "end_datetime = datetime.strptime(monthbatch.iloc[0,1], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "if start_datetime is not None and end_datetime is not None:\n",
    "    stop_time_df = pd.read_sql(\n",
    "        'select * from {} where arrived_at >= datetime(\\'{}\\') and arrived_at <= '\n",
    "        'datetime(\\'{}\\')'.format(stop_event_table_name, start_datetime, end_datetime), con=db)\n",
    "else:\n",
    "    stop_time_df = pd.read_sql_table(stop_event_table_name, db)\n",
    "\n",
    "print('stop_time_df:\\n{}'.format(stop_time_df.describe()))\n",
    "\n",
    "if start_datetime is not None and end_datetime is not None:\n",
    "    vehicle_assignment_df = pd.read_sql(\n",
    "        'select * from {} where start_time >= datetime(\\'{}\\') and start_time <= datetime(\\'{}\\')'.format(driver_schedule_table_name, start_datetime, end_datetime), con=db)\n",
    "else:\n",
    "    vehicle_assignment_df = pd.read_sql_table(driver_schedule_table_name, db)\n",
    "\n",
    "print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "\n",
    "if start_datetime is not None and end_datetime is not None:\n",
    "    warning_df = pd.read_sql(\n",
    "        'select * from {} where loc_time >= \\'{}\\' and loc_time <= \\'{}\\''.format(warning_table_name, start_datetime, end_datetime), con=db)\n",
    "else:\n",
    "    warning_df = pd.read_sql_table(warning_table_name, db)\n",
    "\n",
    "print('warning_df:\\n{}'.format(warning_df.describe()))\n",
    "\n",
    "# extend warning df to include columns that uniquely identify trips so that\n",
    "# warnings assigned to multiple runs can be discovered.\n",
    "warning_ext = pd.DataFrame(\n",
    "    data=np.zeros((warning_df.shape[0], 3), dtype=np.uint32),\n",
    "    columns=['vehicle_id', 'driver_id', 'route_id'], index=warning_df.index)\n",
    "\n",
    "warning_df = pd.concat([warning_df, warning_ext], axis=1)\n",
    "\n",
    "print('warning_df head:\\n{}'.format(warning_df.head(2)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trip_list = assign_warnings_to_trips(\n",
    "    route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\n",
    "\n",
    "print('found {} total trips'.format(len(trip_list)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# assign_warnings_to_trips produces a list of .Trip objects. These get used in construct_hotspot_data_product and construct_longitudinal_data_product\n",
    "type(trip_list[0])\n",
    "\n",
    "trip = trip_list[1]\n",
    "\n",
    "print(trip.warnings.shape[0] > 0) # should be true, otherwise there are no warnings on this trip...\n",
    "\n",
    "print(trip.warnings)\n",
    "\n",
    "warning_df.head() # should vehicle, driver, route be filled in? I don't think so, they should get filled in after completion of assign_warnings_to_trips. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#def construct_hotspot_data_product(trip_list):\n",
    "output_data = np.ndarray((sum([trip.warnings.shape[0] for trip in trip_list]),), dtype=hotspot_type)\n",
    "\n",
    "index = 0\n",
    "\n",
    "output_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for trip in trip_list:\n",
    "    if trip.warnings.shape[0] > 0:\n",
    "        warning_data = trip.warnings.loc[:, ['loc_time', 'warning_name',\n",
    "                                      'latitude', 'longitude']].values\n",
    "\n",
    "    trip_data = np.tile([\n",
    "        trip.route_name, trip.route_id, trip.heading, trip.driver_id,\n",
    "        trip.vehicle_id, trip.bus_number], (warning_data.shape[0], 1))\n",
    "\n",
    "    output_data[index:index + warning_data.shape[0]] = np.apply_along_axis(\n",
    "        to_tuple, 1, np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "    index += warning_data.shape[0]\n",
    "\n",
    "output_data = pd.DataFrame(output_data)\n",
    "\n",
    "# print('output_data: {}'.format(output_data.describe()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unique_warnings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_data = np.ndarray(\n",
    "    (sum([trip.warnings.shape[0] for trip in trip_list]),), dtype=hotspot_type)\n",
    "\n",
    "index = 0\n",
    "\n",
    "for j in range(unique_warnings.shape[0]):\n",
    "    index = np.nonzero(warnings_header == unique_warnings[j])\n",
    "    \n",
    "    if len(index) > 0:\n",
    "        assert len(index) == 1\n",
    "        warning_data[0, index] = counts[j]\n",
    "\n",
    "        \n",
    "    trip_data = np.squeeze(np.concatenate((trip_data, warning_data), axis=1))\n",
    "\n",
    "    output_data[i] = tuple(trip_data)\n",
    "\n",
    "    output_data = pd.DataFrame(output_data)\n",
    "\n",
    "output_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "longitudinal_data = construct_longitudinal_data_product(trip_list)\n",
    "\n",
    "print(longitudinal_data.describe())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hotspot_data = construct_hotspot_data_product(trip_list)\n",
    "\n",
    "print(hotspot_data.describe())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "monthbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_time_df:\n",
      "            stop_id       route_id     vehicle_id  arrival_latitude  \\\n",
      "count  4.102160e+05  410216.000000  410216.000000     410216.000000   \n",
      "mean   1.056570e+05     340.256904    1505.824422         34.046159   \n",
      "std    1.616266e+05      54.368957    1184.900061          0.009901   \n",
      "min    4.219900e+04     296.000000     324.000000         34.018183   \n",
      "25%    9.045300e+04     297.000000     360.000000         34.040870   \n",
      "50%    9.094800e+04     298.000000    1612.000000         34.048503   \n",
      "75%    9.142100e+04     408.000000    1641.000000         34.053009   \n",
      "max    2.294803e+06     409.000000    3809.000000         34.067722   \n",
      "\n",
      "       arrival_longitude  departure_latitude  departure_longitude  \\\n",
      "count      410216.000000       410216.000000        410216.000000   \n",
      "mean         -118.253463           34.046180          -118.253483   \n",
      "std             0.011641            0.009908             0.011670   \n",
      "min          -118.291734           34.017554          -118.291734   \n",
      "25%          -118.259287           34.040987          -118.259103   \n",
      "50%          -118.254120           34.048490          -118.254363   \n",
      "75%          -118.244739           34.053062          -118.244965   \n",
      "max          -118.230484           34.067722          -118.230066   \n",
      "\n",
      "       stop_time_id  \n",
      "count  4.102160e+05  \n",
      "mean   1.586630e+07  \n",
      "std    5.249267e+06  \n",
      "min    9.427196e+06  \n",
      "25%    1.042384e+07  \n",
      "50%    1.740669e+07  \n",
      "75%    2.219738e+07  \n",
      "max    2.294542e+07  \n",
      "vehicle_assignment_df:\n",
      "       vehicle_assignment_id   vehicle_id  route_id    driver_id  \\\n",
      "count             451.000000   451.000000     451.0   451.000000   \n",
      "mean           988418.015521  1608.787140     298.0  2347.399113   \n",
      "std              2098.671135   122.382311       0.0  1656.681142   \n",
      "min            984853.000000   324.000000     298.0   731.000000   \n",
      "25%            986577.500000  1613.000000     298.0  1982.000000   \n",
      "50%            988518.000000  1618.000000     298.0  2023.000000   \n",
      "75%            990249.000000  1631.000000     298.0  2065.000000   \n",
      "max            991934.000000  1642.000000     298.0  9626.000000   \n",
      "\n",
      "         bus_number   badge_number  \n",
      "count    451.000000     451.000000  \n",
      "mean   15320.272727   66670.006652  \n",
      "std      199.755692  136554.662783  \n",
      "min    12334.000000    1067.000000  \n",
      "25%    15326.000000    6051.000000  \n",
      "50%    15331.000000    6088.000000  \n",
      "75%    15343.000000    7278.000000  \n",
      "max    15346.000000  379761.000000  \n",
      "warning_df:\n",
      "          bus_number       latitude      longitude\n",
      "count  193876.000000  193876.000000  193876.000000\n",
      "mean    15259.645469      34.047103    -118.254240\n",
      "std      1506.053804       0.010420       0.012911\n",
      "min     12301.000000      34.018276    -118.291675\n",
      "25%     15323.000000      34.043303    -118.259953\n",
      "50%     15337.000000      34.049411    -118.254001\n",
      "75%     15346.000000      34.053836    -118.243969\n",
      "max     17312.000000      34.067275    -118.231111\n",
      "warning_df head:\n",
      "                     loc_time  bus_number  \\\n",
      "0  2018-02-01 06:44:36.000000       15345   \n",
      "1  2018-02-01 06:45:36.000000       15322   \n",
      "\n",
      "                                          address  \\\n",
      "0    801-807 E 3rd St, Los Angeles, CA 90013, USA   \n",
      "1  850-898 N Broadway, Los Angeles, CA 90012, USA   \n",
      "\n",
      "                       warning_name   latitude   longitude  vehicle_id  \\\n",
      "0                  PDZ - Left Front  34.045796 -118.236208           0   \n",
      "1  ME - Pedestrian In Range Warning  34.064041 -118.237410           0   \n",
      "\n",
      "   driver_id  route_id  \n",
      "0          0         0  \n",
      "1          0         0  \n",
      "route ids among stop times: [296 297 298 408 409]\n",
      "route ids among route stops: [ 296  297 7690  408  409 8435 9212 9270 9736 9960  298]\n",
      "Processing 4 driver_assignments\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8726bce27c95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     trip_list = assign_warnings_to_trips(\n\u001b[1;32m---> 54\u001b[1;33m         route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'found {} total trips'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrip_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c8671c7ec4c5>\u001b[0m in \u001b[0;36massign_warnings_to_trips\u001b[1;34m(route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mdriver_assignments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbus_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroute_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 vehicle_id, warning_df))\n\u001b[1;32m---> 60\u001b[1;33m               \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m               \u001b[0mprocesses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# After debug complete, start here\n",
    "# Iterate over months\n",
    "done_months = [] # track completed months\n",
    "\n",
    "for index, row in monthbatch.iterrows():\n",
    "    \n",
    "    db_path = 'sqlite:///' + path.join(project_root_dir, 'ituran_synchromatics_data.sqlite')\n",
    "\n",
    "    db = create_engine(db_path)\n",
    "\n",
    "    route_stop_df = pd.read_sql_table(route_stop_table_name, db)\n",
    "    # print('route_stop_df:\\n{}'.format(route_stop_df.describe()))\n",
    "\n",
    "    # Allow for a subset of data to be processed based on a date range\n",
    "    start_datetime = datetime.strptime(row['starts'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_datetime = datetime.strptime(row['stops'], '%m/%d/%Y %H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        stop_time_df = pd.read_sql(\n",
    "            'select * from {} where arrived_at >= datetime(\\'{}\\') and arrived_at <= '\n",
    "            'datetime(\\'{}\\')'.format(stop_event_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        stop_time_df = pd.read_sql_table(stop_event_table_name, db)\n",
    "\n",
    "    print('stop_time_df:\\n{}'.format(stop_time_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        vehicle_assignment_df = pd.read_sql(\n",
    "            'select * from {} where start_time >= datetime(\\'{}\\') and start_time <= datetime(\\'{}\\')'.format(driver_schedule_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        vehicle_assignment_df = pd.read_sql_table(driver_schedule_table_name, db)\n",
    "\n",
    "    print('vehicle_assignment_df:\\n{}'.format(vehicle_assignment_df.describe()))\n",
    "\n",
    "    if start_datetime is not None and end_datetime is not None:\n",
    "        warning_df = pd.read_sql(\n",
    "            'select * from {} where loc_time >= \\'{}\\' and loc_time <= \\'{}\\''.format(warning_table_name, start_datetime, end_datetime), con=db)\n",
    "    else:\n",
    "        warning_df = pd.read_sql_table(warning_table_name, db)\n",
    "    \n",
    "    print('warning_df:\\n{}'.format(warning_df.describe()))\n",
    "    \n",
    "    # extend warning df to include columns that uniquely identify trips so that\n",
    "    # warnings assigned to multiple runs can be discovered.\n",
    "    warning_ext = pd.DataFrame(\n",
    "        data=np.zeros((warning_df.shape[0], 3), dtype=np.uint32),\n",
    "        columns=['vehicle_id', 'driver_id', 'route_id'], index=warning_df.index)\n",
    "\n",
    "    warning_df = pd.concat([warning_df, warning_ext], axis=1)\n",
    "\n",
    "    print('warning_df head:\\n{}'.format(warning_df.head(2)))\n",
    "    \n",
    "    trip_list = assign_warnings_to_trips(\n",
    "        route_stop_df, stop_time_df, vehicle_assignment_df, warning_df)\n",
    "    \n",
    "    print('found {} total trips'.format(len(trip_list)))\n",
    "\n",
    "    longitudinal_data = construct_longitudinal_data_product(trip_list)\n",
    "    \n",
    "    longitudinal_data.to_sql(\n",
    "        longitudinal_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "\n",
    "    print(longitudinal_data.describe())\n",
    "\n",
    "    hotspot_data = construct_hotspot_data_product(trip_list)\n",
    "    hotspot_data.to_sql(\n",
    "        hotspot_record_table_name, db, if_exists=if_exists,\n",
    "        chunksize=1000000, index=False)\n",
    "    print(hotspot_data.describe())\n",
    "    \n",
    "    # Track completed months\n",
    "    done_months.append(start_datetime)\n",
    "    print(done_months)\n",
    "    done_months_table = pd.DataFrame(done_months, columns = ['Done'])  \n",
    "    done_months_table.to_sql('completed_months', db, if_exists = 'replace', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
