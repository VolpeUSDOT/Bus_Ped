{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a postgreSQL database -- Jupyter Notebook version\n",
    "\n",
    "*Converted from add_warnigns_with_status_time_open_to_db.py*\n",
    "\n",
    "Create a driver_schedule table, and for each month, and for each route, add all records to that single table\n",
    "\n",
    "We may care to sort the records before adding to the database table\n",
    "\n",
    "First, we need to know if it is safe to use vehicle_assignment_id as the primary key for driver schedule records, so we test for uniqueness across all data files: for each VehiclesThatRanRoute file across all routes and months, read vehicle_assignment_id values into an array, count the unique array entries and compare for equality with the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path, listdir\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_warning_name(elem):\n",
    "  warning_name = elem.split(' - StatusTimeOpen:')[0]\n",
    "  return warning_name if warning_name in warning_name_list else None\n",
    "\n",
    "def preprocess_bus_number(elem):\n",
    "  return elem.split()[-1]\n",
    "\n",
    "#assume that the warnings folder only has warning spreadsheet files as children\n",
    "project_root_dir = r'\\\\vntscex.local\\DFS\\3BC-Share$_Mobileye_Data\\Data\\Data Integration' \n",
    "data_root_dir = path.join(project_root_dir, 'warnings') # 'warnings'\n",
    "\n",
    "warning_data = []\n",
    "\n",
    "warning_name_list = [\n",
    "  'ME - Pedestrian Collision Warning', 'ME - Pedestrian In Range Warning',\n",
    "  'PCW-LF', 'PCW-LR', 'PCW-RR', 'PDZ - Left Front', 'PDZ-LR', 'PDZ-R',\n",
    "  'Safety - Braking - Aggressive', 'Safety - Braking - Dangerous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DASH_Report_2018_01_01_to_2018_01_31.xlsx\n",
      "0:00:00.333537\n",
      "DASH_Report_2018_02_01_to_2018_02_05.xlsx\n",
      "0:00:03.029540\n",
      "DASH_Report_2018_02_06_to_2018_02_10.xlsx\n",
      "0:00:12.274168\n",
      "DASH_Report_2018_02_10_to_2018_02_15.xlsx\n",
      "0:00:21.840359\n",
      "DASH_Report_2018_02_16_to_2018_02_20.xlsx\n",
      "0:00:33.492384\n",
      "DASH_Report_2018_02_21_to_2018_02_25.xlsx\n",
      "0:00:49.086944\n",
      "DASH_Report_2018_02_26_to_2018_02_28.xlsx\n",
      "0:00:59.833797\n",
      "DASH_Report_2018_03_01_to_2018_03_05.xlsx\n",
      "0:01:20.298990\n",
      "DASH_Report_2018_03_06_to_2018_03_10.xlsx\n",
      "0:01:58.301012\n",
      "DASH_Report_2018_03_11_to_2018_03_15.xlsx\n",
      "0:02:33.913621\n",
      "DASH_Report_2018_03_16_to_2018_03_20.xlsx\n",
      "0:03:00.708066\n",
      "DASH_Report_2018_03_21_to_2018_03_25.xlsx\n",
      "0:03:19.979141\n",
      "DASH_Report_2018_03_26_to_2018_03_30.xlsx\n",
      "0:03:51.775138\n",
      "DASH_Report_2018_03_31.xlsx\n",
      "0:03:53.543178\n",
      "DASH_Report_2018_04_01_to_2018_04_05.xlsx\n",
      "0:04:23.677184\n",
      "DASH_Report_2018_04_06_to_2018_04_10.xlsx\n",
      "0:04:46.605404\n",
      "DASH_Report_2018_04_11_to_2018_04_15.xlsx\n",
      "0:05:08.941260\n",
      "DASH_Report_2018_04_21_to_2018_04_25.xlsx\n",
      "0:05:31.836758\n",
      "DASH_Report_2018_04_26_to_2018_04_30.xlsx\n",
      "0:05:57.579933\n",
      "DASH_Report_2018_05_01_to_2018_05_05.xlsx\n",
      "0:06:26.489742\n",
      "DASH_Report_2018_05_06_to_2018_05_10.xlsx\n",
      "0:06:56.625515\n",
      "DASH_Report_2018_05_11_to_2018_05_15.xlsx\n",
      "0:07:20.909484\n",
      "DASH_Report_2018_05_16_to_2018_05_20.xlsx\n",
      "0:07:47.228614\n",
      "DASH_Report_2018_05_21_to_2018_05_25.xlsx\n",
      "0:08:22.374404\n",
      "DASH_Report_2018_05_26_to_2018_05_31.xlsx\n",
      "0:08:46.527949\n",
      "DASH_Report_2018_06_01_to_2018_06_05.xlsx\n",
      "0:09:11.199483\n",
      "DASH_Report_2018_06_06_to_2018_06_10.xlsx\n",
      "0:09:35.986280\n",
      "DASH_Report_2018_06_11_to_2018_06_14.xlsx\n",
      "0:10:05.919535\n",
      "DASH_Report_2018_06_15_to_2018_06_19.xlsx\n",
      "0:10:32.037590\n",
      "DASH_Report_2018_06_20_to_2018_06_24.xlsx\n",
      "0:10:56.790688\n",
      "DASH_Report_2018_06_25_to_2018_06_29.xlsx\n",
      "0:11:34.111455\n",
      "DASH_Report_2018_06_30.xlsx\n",
      "0:11:35.647266\n",
      "DASH_Report_2018_07_01_to_2018_07_05.xlsx\n",
      "0:12:01.553846\n",
      "DASH_Report_2018_07_06_to_2018_07_10.xlsx\n",
      "0:12:25.553758\n",
      "DASH_Report_2018_07_11_to_2018_07_15.xlsx\n",
      "0:12:49.512965\n",
      "DASH_Report_2018_07_16_to_2018_07_20 (1).xlsx\n",
      "0:13:25.084600\n",
      "DASH_Report_2018_07_16_to_2018_07_20.xlsx\n",
      "0:14:01.531630\n",
      "DASH_Report_2018_07_21_to_2018_07_25.xlsx\n",
      "0:14:25.765728\n",
      "DASH_Report_2018_07_26_to_2018_07_31.xlsx\n",
      "0:14:56.624144\n",
      "ituran_synchromatics_data_DanTest.sqlite\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\vntscex.local\\\\DFS\\\\3BC-Share$_Mobileye_Data\\\\Data\\\\Data Integration\\\\warnings\\\\ituran_synchromatics_data_DanTest.sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6281e5fcda1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                        \u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                        \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loc_time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bus_number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'address'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'warning_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                        header=None, parse_dates=[0])#, dtype={0: object, 1: object, 3: object, 4: object, 5: np.float64, 6: np.float64})\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# print(df.describe())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\vntscex.local\\\\DFS\\\\3BC-Share$_Mobileye_Data\\\\Data\\\\Data Integration\\\\warnings\\\\ituran_synchromatics_data_DanTest.sqlite'"
     ]
    }
   ],
   "source": [
    "StartTime = datetime.datetime.now()\n",
    "\n",
    "allfiles = listdir(data_root_dir)\n",
    "# skip one bad file\n",
    "usefiles = (x for x in allfiles if x not in 'DASH_Report_2018_04_16_to_2018_04_20.xlsx')\n",
    "\n",
    "for file_name in usefiles:\n",
    "    \n",
    "    file_path = path.join(data_root_dir, file_name)\n",
    "    print(file_name)\n",
    "    # file_path = path.join(data_root_dir, listdir(data_root_dir)[0])\n",
    "    # print(file_path)\n",
    "\n",
    "    # only read columns loc_time (0), Vehicle Name (2), Address (7),\n",
    "    # warning_name (9), Latitude (11), Longitude (12), and skip the Ituran header\n",
    "    # (first 7 rows)\n",
    "    df = pd.read_excel(file_path,\n",
    "                       skiprows = [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "                       usecols = [0, 1, 3, 4, 5, 6],\n",
    "                       names=['loc_time', 'bus_number', 'address', 'warning_name', 'latitude', 'longitude'],\n",
    "                       header=None, parse_dates=[0])#, dtype={0: object, 1: object, 3: object, 4: object, 5: np.float64, 6: np.float64})\n",
    "\n",
    "    # print(df.describe())\n",
    "    # df.head()\n",
    "    # remove extraneous StatusTimeOpen suffix from warning messages and set other\n",
    "    # messages to null, then drop those null records\n",
    "    df.loc[:, 'warning_name'] = df.loc[:, 'warning_name'].apply(\n",
    "    preprocess_warning_name)\n",
    "\n",
    "    df.loc[:, 'bus_number'] = df.loc[:, 'bus_number'].apply(\n",
    "    preprocess_bus_number).astype(np.uint32)\n",
    "    # print(df.head().loc[:, 'warning_name'])\n",
    "\n",
    "    df.dropna(subset=['warning_name'], inplace=True)\n",
    "    # print(df.describe())\n",
    "    # print(df.head().loc[:, 'warning_name'])\n",
    "\n",
    "   # print(df.head(2))\n",
    "   # print(df.dtypes)\n",
    "    EndTime = datetime.datetime.now()\n",
    "    print(EndTime-StartTime)\n",
    "    warning_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_data = pd.concat(\n",
    "  warning_data, ignore_index=True, verify_integrity=True)\n",
    "\n",
    "print('init warning_data:\\n{}'.format(warning_data.describe()))\n",
    "\n",
    "# count the unique stop_tim_id and compare with the number of records to\n",
    "# identify duplicates (and do it per route in case duplicates occur across\n",
    "# routes but not within a single route - which is okay) we learn that indeed\n",
    "# the stop ids are unique within a given route\n",
    "# find_duplicates(warning_data)\n",
    "\n",
    "# drop duplicates if found\n",
    "warning_data.drop_duplicates(inplace=True)\n",
    "\n",
    "print('de-duplicated warning_data:\\n{}'.format(warning_data.describe()))\n",
    "print('\\n{}'.format(warning_data.head()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We temporarily also drop records with missing values to prove our concept.\n",
    "Key attributes that require values include 1) __, 2) route_id,\n",
    "3) vehicle_id, 4) arrived_at, 5) departed_at, and 6) stop_time_id. For now,\n",
    "we exclude the stop_id because many relevant records have missing stop_ids.\n",
    "\n",
    "TODO: Infer missing values where possible using warning and route data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key_column_names = ['route_id', 'vehicle_id', 'arrived_at', 'departed_at']\n",
    "#\n",
    "# warning_data.dropna(subset=key_column_names, inplace=True)\n",
    "\n",
    "# we make no assumption about the order in which source files are input\n",
    "warning_data.sort_values(['loc_time', 'bus_number'], inplace=True)\n",
    "\n",
    "# reset indices after sorting records\n",
    "warning_data.set_index(pd.RangeIndex(warning_data.shape[0]), inplace=True)\n",
    "\n",
    "# excel_writer = pd.ExcelWriter('processed_warnings.xlsx')\n",
    "#\n",
    "# chunk_size = pow(2, 20) - 1\n",
    "#\n",
    "# idx_limit = warning_data.shape[0]\n",
    "#\n",
    "# for i in range(int(ceil(idx_limit / chunk_size))):\n",
    "#   chunk = warning_data.iloc[i * chunk_size:max((i + 1) * chunk_size, idx_limit)]\n",
    "#\n",
    "#   print('{}_th chunk_data:\\n{}\\n{}\\n'.format(i, chunk.describe(), chunk.head()))\n",
    "#\n",
    "#   chunk.to_excel(excel_writer, 'warnings_{}'.format(i), index=False)\n",
    "#\n",
    "# excel_writer.save()\n",
    "        \n",
    "#db_path = 'sqlite:///ituran_synchromatics_data_DanTest.sqlite'\n",
    "\n",
    "db_path = 'sqlite:///' + path.join(project_root_dir, 'ituran_synchromatics_data_DanTest.sqlite')\n",
    "db = create_engine(db_path)\n",
    "\n",
    "# poor performance has been observed when adding more than one million records\n",
    "# at a time\n",
    "warning_data.to_sql(\n",
    "  'warning', db, if_exists='replace', chunksize=1000000, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
